{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Training and Tuning of Deep Learning Models in Python\n",
    "\n",
    "The lecture has introduced you to foundations of neural networks. Therefore, in today's tutorial notebook we will revisit the forward pass performed in shallow and deep neural networks on tabular data. This will help us understand the functionality behind **sklearn's MLPRegressor**, as well as which hyperparameters of neural networks can be tuned to improve their performance. \n",
    "\n",
    "Here is the outline of the notebook:\n",
    "*   Forward pass of shallow and deep neural networks in numpy (Demo). \n",
    "*   Implementation of two MLPRegressor models with varying depth using sklearn (Excercise 1).\n",
    "*   Tuning of MLPRegressor using Optuna (Excercise 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Forward Pass of shallow and deep Neural Networks with Numpy** (DEMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1. Forward Pass in Neural Networks with a single hidden Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's revisit the forward pass in a shallow neural network, using the below illustration: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Shallow Neural Network](https://github.com/Humboldt-WI/demopy/raw/main/Shallow_Neural_Network_Forward_Pass.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a neural network with **<em>m</em>** input variables, which are fed to a single hidden layer with **<em>w</em>** = 2 units. The hidden layer makes use of the activation function **<em>g</em>** to transform the latent representation of the inputs nonlinearly. The output of the nonlinear transformation is then fed to the final layer, i.e., the prediction layer, which produces the estimates of the target variable **<em>y</em>**.<br>\n",
    "\n",
    "Now, imagine you have a batch of 20 samples with 5 predictor features and a single continuous target variable. You are tasked to implement the forward pass of the above-described neural network with numpy. First, we will simulate our batch of data by drawing samples from a standard normal distribution using numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch of simulated data:  (20, 5)\n"
     ]
    }
   ],
   "source": [
    "#Simulation of a batch of 20 samples with 5 features:\n",
    "w=2\n",
    "m=5\n",
    "num_samples=20\n",
    "data_batch=np.random.normal(size=m*num_samples,loc=0.0,scale=1.0).reshape(num_samples,m)\n",
    "#We create an artificial target variable using the exponential function in numpy:\n",
    "target=np.exp(np.dot(data_batch,np.random.normal(size=m).reshape(-1,1)))\n",
    "print('Shape of batch of simulated data: ',data_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will initialize the trainable parameters of the hidden layer and the output layer of the shallow network. The shape of the weight matrices in the hidden layer  and the output layer are **<em>(m,w)</em>** and **<em>(w,1)</em>**. The shape of the bias weights is determined by the  number of units in each layer. Since one of the main advantages of using neural networks is their ability to approximate nonlinear relationships, we will define two nonlinear activation functions, i.e., ReLU and Tanh. We will use both to nonlinearly transform the latent feature space produced by the matrix multiplication of the network weights with the synthetic batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the trainable weight matrices of the shallow neural network:\n",
      "- W of hidden layer: (5, 2)\n",
      "- Bias of hidden layer: (2,) \n",
      "\n",
      "- W of output layer: (2, 1)\n",
      "- Bias of output layer: (1,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_hidden_layer=np.random.normal(size=m*w).reshape(m,w)\n",
    "bias_hidden_layer=np.random.normal(size=w)\n",
    "\n",
    "w_output_layer=np.random.normal(size=w).reshape(-1,1)\n",
    "bias_output_layer=np.random.normal(size=1)\n",
    "\n",
    "print('Shape of the trainable weight matrices of the shallow neural network:')\n",
    "print('- W of hidden layer:',w_hidden_layer.shape)\n",
    "print('- Bias of hidden layer:',bias_hidden_layer.shape,'\\n')\n",
    "print('- W of output layer:',w_output_layer.shape)\n",
    "print('- Bias of output layer:',bias_output_layer.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the linear latent representation of the input variables:  (20, 2)\n"
     ]
    }
   ],
   "source": [
    "#Linear latent feature space of inputs: generated with matrix multiplication,\n",
    "#we implement the latter with the function numpy.dot:\n",
    "linear_latent_representation=np.dot(data_batch,w_hidden_layer) + bias_hidden_layer\n",
    "print('Shape of the linear latent representation of the input variables: ',linear_latent_representation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix multiplication of the weights with the input variables produces a linear latent representation consisting of 2 units for each of the 20 synthetic data samples. The bias weights array has only 2 trainable weights. At first sight, the addition of one-dimensional array to a two-dimensional matrix with the shape (20,2) seems conceptually impossible in the context of linear algebra. However, due to broadcasting, numpy efficiently adds the bias weights to each row of the latent representation. For more details on broadcasting, we refer the reader to: https://numpy.org/doc/stable/user/basics.broadcasting.html. <br>\n",
    "\n",
    "Next, we create a well-documented function implementing ReLU and Tanh: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_func(x:np.ndarray,\n",
    "                   activation_name:str)->np.ndarray:\n",
    "    \"\"\"Computes ReLU or Tanh transformations of the inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    x: np.ndarray\n",
    "        The linearly transformed inputs.\n",
    "    activation_name: str\n",
    "        The name of the activation function, i.e., ReLU or Tanh.\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    nonlinear_x: np.ndarray\n",
    "        The nonlinearly transformed inputs.\n",
    "    \n",
    "    Raises:\n",
    "    ----------\n",
    "    ValueError: If specified activation_name is not in the list [ReLU, Tanh].\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation_name not in ['ReLU','Tanh']:\n",
    "        raise ValueError(f'The currently specified activation function {activation_name} is not in the list of supported nonlinearities.')\n",
    "        \n",
    "    if activation_name=='Tanh':\n",
    "        nonlinear_x=np.tanh(x)\n",
    "    else:\n",
    "        nonlinear_x=x*(x>0.0)\n",
    "        \n",
    "    return nonlinear_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above function, we specify the type of the input parameters and the type of the output values of our function. Also, we provide a brief summary of what the function does, what the input parameters and the return value represent. Proper documentation of your functions improves the readability of your code a lot especially for someone, who is examining your code for the first time. For more details on the annotation of python functions, we refer the reader to: https://peps.python.org/pep-3107/#fundamentals-of-function-annotations. <br>\n",
    "\n",
    "Next, we will pass the linearly weighted inputs through our nonlinear activations, and we will plot the distribution of the resulting values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relu_latent=nonlinear_func(x=linear_latent_representation,activation_name='ReLU')\n",
    "tanh_latent=nonlinear_func(x=linear_latent_representation,activation_name='Tanh')\n",
    "\n",
    "fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,3))\n",
    "ax[0].hist(relu_latent.flatten())\n",
    "ax[0].set_title('ReLU latent Feature Space')\n",
    "\n",
    "ax[1].hist(tanh_latent.flatten())\n",
    "ax[1].set_title('Tanh latent Feature Space')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above histogram plots highlight the difference in the distribution of the latent features. While ReLU produces a right-skewed representation of the inputs, Tanh generates a bimodal latent feature space. Generally, the ReLU activation is prefered over Tanh in neural networks, especially in deep neural models. However, Tanh could also be applied in rather shallow neural models. The main limitation of Tanh, and generally speaking of activations with a lower and an upper bound, is that output values very close to the saturation regions, i.e., -1 and 1 in case of Tanh, receive almost no gradients in the backward pass. Therefore, bounded activation functions suffer from the vanishing gradients problem.<br>\n",
    "\n",
    "Next, we produce the predictions of our synthetic target:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape:  (20, 1)\n"
     ]
    }
   ],
   "source": [
    "relu_predictions=np.dot(relu_latent,w_output_layer)+bias_output_layer\n",
    "tanh_predictions=np.dot(tanh_latent,w_output_layer)+bias_output_layer\n",
    "print('Predictions shape: ',relu_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the quality of the estimations, we define a function computing the mean-squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(true_target:np.ndarray,\n",
    "        predictions:np.ndarray)->np.float64:\n",
    "    '''\n",
    "    Computes the mean-squared error (MSE) between the true values of the target variable and the predictions of an ML model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    true_target: np.ndarray\n",
    "        The true values.\n",
    "    predictions: np.ndarray\n",
    "        The estimation of the target values.\n",
    "        \n",
    "    Returns:\n",
    "    -----------\n",
    "    mse_score: np.float\n",
    "        The error between the true values and the predictions measured in terms of MSE.\n",
    "    '''\n",
    "    mse_score=np.mean((true_target-predictions)**2)\n",
    "    return mse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE from ReLU-Network:  13.15\n",
      "MSE from Tanh-Network:  14.772\n"
     ]
    }
   ],
   "source": [
    "print('MSE from ReLU-Network: ',round(mse(true_target=target,predictions=relu_predictions),3))\n",
    "print('MSE from Tanh-Network: ',round(mse(true_target=target,predictions=tanh_predictions),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have performed the forward pass of a neural network with a single hidden layer. Without any training of the two versions of the neural network the results in terms of MSE seem pretty close to each other, as both versions use the same randomly initialized weights in the hidden layer. We will use our mse function in Section 2 and Section 3, where we will compare the performance of two trained neural networks and we will implement neural network tuning, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1. Forward Pass in deep Neural Networks with several hidden Layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on to more coding, let's recap the forward pass in deep neural networks: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deep Neural Network](https://github.com/Humboldt-WI/demopy/raw/main/Deep_Neural_Networks_Forward_Pass.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above visualization shows that in a deep neural network the layers are structured in a chain, where the output of each layer is fed as an input to every following layer. By \"fed\", we mean that we compute the matrix multiplication between the latent representation of the previous layer and the trainable weights of the current layer, add the biases and apply a nonlinear activation function. Therefore, the output shape of each hidden layer determines the shape of the weight matrices of every following hidden layer.<br>\n",
    "\n",
    "Below, we create a function, which computes the forward pass of an arbitrarily ReLU-based deep neural network implemented in numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_net(hidden_units:list,\n",
    "                    inputs:np.ndarray,\n",
    "                    print_layer_shape:bool)->np.ndarray:\n",
    "    '''\n",
    "    Computes the forward pass with an arbitrarily deep feedforward neural network.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    hidden_units: list\n",
    "        A list of hidden units, which also determines the number of hidden layers in the network.\n",
    "    inputs: np.ndarray\n",
    "        A two-dimensional numpy matrix containing the data samples in the rows, and the predictor variables in the columns.\n",
    "    print_layer_shape: bool\n",
    "        Determines whether to print the shape of the latent representation produced by each hidden layer and the final prediction layer.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    predictions: np.ndarray\n",
    "        The estimation of the target.\n",
    "    '''\n",
    "    \n",
    "    current_linear_representation=inputs.copy()\n",
    "    if print_layer_shape==True:\n",
    "        print('Inputs shape: ',inputs.shape,'\\n')\n",
    "    \n",
    "\n",
    "    for nr_units_idx in range(0,len(hidden_units)):\n",
    "        if nr_units_idx==0:\n",
    "            current_weights=np.random.normal(size=inputs.shape[1]*hidden_units[nr_units_idx]).reshape(inputs.shape[1],hidden_units[nr_units_idx])\n",
    "        else:\n",
    "            current_weights=np.random.normal(size=previous_matrix_shape[1]*hidden_units[nr_units_idx]).reshape(previous_matrix_shape[1],hidden_units[nr_units_idx])\n",
    "        current_bias_weights=np.random.normal(size=hidden_units[nr_units_idx])\n",
    "\n",
    "        #At each hidden layer we overwrite the linear representation passed to the nonlinearity: \n",
    "        current_linear_representation=np.dot(current_linear_representation,current_weights)+current_bias_weights\n",
    "\n",
    "        #ReLU-based transformation:\n",
    "        current_nonlinear_representation=nonlinear_func(x=current_linear_representation,\n",
    "                                                        activation_name='ReLU')\n",
    "        previous_matrix_shape=current_weights.shape\n",
    "\n",
    "        if print_layer_shape==True:\n",
    "            print('Output shape of ',(nr_units_idx+1),'.hidden layer: ',current_nonlinear_representation.shape,'\\n')\n",
    "    \n",
    "    #Compute the predictions:\n",
    "    output_layer_weights=np.random.normal(size=current_nonlinear_representation.shape[1]).reshape(-1,1)\n",
    "    bias_output_layer=np.random.normal(size=1).reshape(-1,1)\n",
    "    \n",
    "    predictions=np.dot(current_nonlinear_representation,output_layer_weights)+bias_output_layer\n",
    "    if print_layer_shape==True:\n",
    "        print('Output shape of prediction layer: ',predictions.shape,'\\n')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape:  (20, 5) \n",
      "\n",
      "Output shape of  1 .hidden layer:  (20, 100) \n",
      "\n",
      "Output shape of  2 .hidden layer:  (20, 50) \n",
      "\n",
      "Output shape of  3 .hidden layer:  (20, 10) \n",
      "\n",
      "Output shape of prediction layer:  (20, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_deep_net=deep_neural_net(hidden_units=[100,50,10],\n",
    "                                     inputs=data_batch,\n",
    "                                     print_layer_shape=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Implementation of deep feed-forward regression neural networks using sklearn.** <br>(Excercise 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, first, we will import a house pricing dataset from tensorflow, i.e., boston housing dataset. Afterward, we will examine some basic statistical characteristics of the features. Once the data is rescaled, we will train an MLPRegressor from sklearn to forecast the median price values of boston houses (our target variable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: (404, 13) \n",
      "Shape of test data: (102, 13)\n"
     ]
    }
   ],
   "source": [
    "# this will import and split the data 80-20% by default:\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n",
    "\n",
    "print('Shape of train data:',x_train.shape,\n",
    "'\\nShape of test data:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptions of the features are the following (more details about this dataset can be found in [http://lib.stat.cmu.edu/datasets/boston](http://lib.stat.cmu.edu/datasets/boston))<br>\n",
    "| # | Variable | Description |\n",
    "|---|---|---|\n",
    "| 1 | CRIM | per capita crime rate by town |\n",
    "| 2 | ZN | proportion of residential land zoned for lots over 25,000 sq.ft. |\n",
    "| 3 | INDUS | proportion of non-retail business acres per town |\n",
    "| 4 | CHAS | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n",
    "| 5 | NOX | nitric oxides concentration (parts per 10 million) |\n",
    "| 6 | RM | average number of rooms per dwelling |\n",
    "| 7 | AGE | proportion of owner-occupied units built prior to 1940 |\n",
    "| 8 | DIS | weighted distances to five Boston employment centres |\n",
    "| 9 | RAD | index of accessibility to radial highways |\n",
    "| 10 | TAX | full-value property-tax rate per $10,000 |\n",
    "| 11 | PTRATIO | pupil-teacher ratio by town |\n",
    "| 12 | B | 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town |\n",
    "| 13 | LSTAT | % lower status of the population |\n",
    "\n",
    "So, we have 404 samples to train and 102 to test, each with 13 numerical features. The target is the median values of homes. Let's have a quick look at the predictor features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.745111</td>\n",
       "      <td>11.480198</td>\n",
       "      <td>11.104431</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.557356</td>\n",
       "      <td>6.267082</td>\n",
       "      <td>69.010644</td>\n",
       "      <td>3.740271</td>\n",
       "      <td>9.440594</td>\n",
       "      <td>405.898515</td>\n",
       "      <td>18.475990</td>\n",
       "      <td>354.783168</td>\n",
       "      <td>12.740817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.240734</td>\n",
       "      <td>23.767711</td>\n",
       "      <td>6.811308</td>\n",
       "      <td>0.241238</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.709788</td>\n",
       "      <td>27.940665</td>\n",
       "      <td>2.030215</td>\n",
       "      <td>8.698360</td>\n",
       "      <td>166.374543</td>\n",
       "      <td>2.200382</td>\n",
       "      <td>94.111148</td>\n",
       "      <td>7.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>5.874750</td>\n",
       "      <td>45.475000</td>\n",
       "      <td>2.077100</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.225000</td>\n",
       "      <td>374.672500</td>\n",
       "      <td>6.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.268880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.198500</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>3.142300</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>11.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.674808</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.609000</td>\n",
       "      <td>94.100000</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.157500</td>\n",
       "      <td>17.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.725000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.710300</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     3.745111   11.480198   11.104431    0.061881    0.557356    6.267082   \n",
       "std      9.240734   23.767711    6.811308    0.241238    0.117293    0.709788   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081437    0.000000    5.130000    0.000000    0.453000    5.874750   \n",
       "50%      0.268880    0.000000    9.690000    0.000000    0.538000    6.198500   \n",
       "75%      3.674808   12.500000   18.100000    0.000000    0.631000    6.609000   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.725000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    69.010644    3.740271    9.440594  405.898515   18.475990  354.783168   \n",
       "std     27.940665    2.030215    8.698360  166.374543    2.200382   94.111148   \n",
       "min      2.900000    1.129600    1.000000  188.000000   12.600000    0.320000   \n",
       "25%     45.475000    2.077100    4.000000  279.000000   17.225000  374.672500   \n",
       "50%     78.500000    3.142300    5.000000  330.000000   19.100000  391.250000   \n",
       "75%     94.100000    5.118000   24.000000  666.000000   20.200000  396.157500   \n",
       "max    100.000000   10.710300   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  404.000000  \n",
       "mean    12.740817  \n",
       "std      7.254545  \n",
       "min      1.730000  \n",
       "25%      6.890000  \n",
       "50%     11.395000  \n",
       "75%     17.092500  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desriptive statistics show that the is a big variation in the mean and the standard deviation of the predictor variables. This indicates that the input features have different scales. For this reason, we will standardize our test dataset based on the statistics computed on the rescaled train dataset. With data rescaling, we ensure that no predictor dominates the input feature space due to varying variable scale. This, in turn, improves the stability of the training process, and facilitates faster convergence. The StandardScaler can be imported from sklearn.preprocessing: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html. Take a look at the code example provided under the link, and standardize the boston housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler;\n",
    "#Data rescaling:\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "\n",
    "x_train_scaled = scaler.transform(X=x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot the distribution of the target variable on the train set, and examine whether it is also necessary to standardize the target in addition to the predictor variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq8AAAHUCAYAAAAUbMECAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACDa0lEQVR4nO3dd3xT9f4/8NfJaJruRfegLWWWVvYeikUBkXGdoILiFX+CC1G+iqN4BRxXXFxxIypLvaAoQ6pA2cospbSllC466UxHmqbJ+f1RmmtpgY60J2lfz8cjD8jJyfu8cz5J++4nn/P5CKIoiiAiIiIisgIyqRMgIiIiImouFq9EREREZDVYvBIRERGR1WDxSkRERERWg8UrEREREVkNFq9EREREZDVYvBIRERGR1WDxSkRERERWg8UrEREREVkNFq9ErfD1119DEATTzdbWFt7e3rj55puxcuVKFBQUNHpOdHQ0BEFo0XGqqqoQHR2Nffv2teh5TR2re/fuuOOOO1oU50Y2bNiA999/v8nHBEFAdHS0WY9nbn/88QcGDx4Me3t7CIKAn376qdE+48ePb9DW17pZ2mttyXvngw8+gCAI2LVr1zX3+fzzzyEIArZs2WKW/Lp37465c+e26rmCIGDhwoU33G/fvn0QBKHFn58bSU1NhUqlwpEjR8waFwAOHz6M6OholJaWmj02AMydOxfdu3dv1XO//PJL+Pn5obKy0rxJEbWUSEQttnbtWhGAuHbtWvHIkSPi/v37xR9//FF85plnRGdnZ9HNzU2MiYlp8JysrCzxyJEjLTrO5cuXRQDia6+91qLnNXWsoKAgccqUKS2KcyNTpkwRg4KCmnzsyJEjYlZWllmPZ05Go1F0c3MThw8fLv7+++/ikSNHxOLi4kb7JSQkiEeOHDHdXn755QZtX3+ztNfakvdOYWGhqFKpxLvvvvua+4wYMULs1q2bWFNTY5b8Tp48KV64cKFVzwUgLliw4Ib77d27VwQg7t27t1XHuZbp06eb/bNU75133hEBiGlpae0S/8KFC+LJkydb9Vy9Xi+GhYWJr776qpmzImoZhYR1M5HVCw8Px+DBg033//GPf+DZZ5/F6NGjMXPmTKSkpMDLywsA4O/vD39//3bNp6qqCnZ2dh1yrBsZPny4pMe/kZycHBQXF2PGjBmYMGHCNffr27dvg/tJSUkAGrd9a9W3mZTc3d0xbdo0/PTTTygqKoK7u3uDx5OSknDkyBE899xzUCqVbTqWVquFWq3GgAED2hRHKomJifjpp5+u20vdkerPZ3OFhoa2+lgKhQLz58/Hv/71LyxZskTy9y11XRw2QGRmgYGBePfdd1FeXo5PP/3UtL2pr/L37NmD8ePHw93dHWq1GoGBgfjHP/6BqqoqpKeno1u3bgCAZcuWmb6erv+qtT7eyZMncdddd8HV1dX0i+l6QxS2bt2KiIgI2NraIiQkBB9++GGDx+uHRKSnpzfYfvVXsOPHj8f27duRkZHR4Ovzek19lX727FlMmzYNrq6usLW1xU033YR169Y1eZyNGzdi6dKl8PX1hZOTE2699VYkJydf+8T/zcGDBzFhwgQ4OjrCzs4OI0eOxPbt202PR0dHm4r7JUuWQBCEVn+VCgAxMTGYNm0a/P39YWtrix49emD+/PkoLCxssN/12kyn0+G5556Dt7c37OzsMHbsWJw4caLJr9fz8vIwf/58+Pv7w8bGBsHBwVi2bBlqa2sB4IbvnabMmzcPNTU12LBhQ6PH1q5dCwB45JFHTDGHDRsGNzc3ODk5YeDAgfjyyy8himKD59UPVdmyZQsGDBgAW1tbLFu2zPTY3/Oprq7Gc889h5tuugnOzs5wc3PDiBEj8PPPP18z508//RQ9e/aESqVC3759sWnTpmvu+3fHjx/HnXfeCTc3N9ja2mLAgAH4/vvvm/XcNWvWwNvbG1FRUaZt//rXv6BQKJCVldVo/0ceeQTu7u6orq6+Yezo6Gg8//zzAIDg4GBTu9V/5q53Pv/zn/9g7Nix8PT0hL29Pfr374+3334ber2+wTGaGjZQPwzj22+/RZ8+fWBnZ4fIyEj8+uuvjXKcPXs2NBpNs881UXtgzytRO5g8eTLkcjn2799/zX3S09MxZcoUjBkzBl999RVcXFyQnZ2NXbt2oaamBj4+Pti1axduv/12zJs3D48++igAmIqSejNnzsR9992Hxx9//IZj0U6fPo1nnnkG0dHR8Pb2xvr16/H000+jpqYGixcvbtFr/Pjjj/HYY48hNTUVW7duveH+ycnJGDlyJDw9PfHhhx/C3d0d3333HebOnYv8/Hy88MILDfZ/6aWXMGrUKHzxxRfQaDRYsmQJpk6disTERMjl8mseJzY2FlFRUYiIiMCXX34JlUqFjz/+GFOnTsXGjRtx77334tFHH0VkZCRmzpyJJ598ErNmzYJKpWrR6/+71NRUjBgxAo8++iicnZ2Rnp6OVatWYfTo0YiPj2/UW9lUmz388MPYvHkzXnjhBdxyyy04d+4cZsyYAY1G0+C5eXl5GDp0KGQyGV599VWEhobiyJEjeOONN5Ceno61a9c2+73zd7feeiuCgoLw1Vdf4cknnzRtNxgM+PbbbzF8+HBTL3R6ejrmz5+PwMBAAMDRo0fx5JNPIjs7G6+++mqDuCdPnkRiYiJefvllBAcHw97evsnj63Q6FBcXY/HixfDz80NNTQ1+//13zJw5E2vXrsVDDz3UYP9t27Zh7969eP3112Fvb4+PP/4Y999/PxQKBe66665rvs69e/fi9ttvx7Bhw/DJJ5/A2dkZmzZtwr333ouqqqobjsPdvn07xo4dC5nsf30/8+fPx/Lly/Hpp5/ijTfeMG0vLi7Gpk2bsHDhQtja2l43LgA8+uijKC4uxkcffYQtW7bAx8cHQMPe/2udz9TUVMyaNQvBwcGwsbFBXFwcli9fjqSkJHz11Vc3PPb27dtx7NgxvP7663BwcMDbb7+NGTNmIDk5GSEhIab9vL290bt3b2zfvt30xwxRh5N63AKRNaof83rs2LFr7uPl5SX26dPHdP+1114T//6R+/HHH0UA4unTp68Z43rjFuvjNTX+7OpjiWLdmFdBEBodLyoqSnRychIrKysbvLarx9w1NX7wemNer877vvvuE1UqlZiZmdlgv0mTJol2dnZiaWlpg+NMnjy5wX7ff/+9COCG44aHDx8uenp6iuXl5aZttbW1Ynh4uOjv7y8ajUZRFEUxLS1NBCC+88471413tRu1vdFoFPV6vZiRkSECEH/++WfTY9dqs4SEBBGAuGTJkgbbN27cKAIQ58yZY9o2f/580cHBQczIyGiw77///W8RgJiQkCCKYuvGS9fn9/cxkb/88osIQPz888+bfI7BYBD1er34+uuvi+7u7qbzK4p17zm5XC4mJyc3el5QUFCD13W12tpaUa/Xi/PmzRMHDBjQ4DEAolqtFvPy8hrs37t3b7FHjx6mbU29Z3v37i0OGDBA1Ov1DWLecccdoo+Pj2gwGK6ZU35+vghAfPPNNxs9NmfOHNHT01PU6XSmbW+99ZYok8laNH71emNer3c+/66+Tb755htRLpc3GMs9Z86cRp9ZAKKXl5eo0WhM2/Ly8kSZTCauXLmyUfzZs2eLXl5ezX5NRObGYQNE7US86ivUq910002wsbHBY489hnXr1uHixYutOs4//vGPZu/br18/REZGNtg2a9YsaDQanDx5slXHb649e/ZgwoQJCAgIaLB97ty5qKqqanTl9p133tngfkREBAAgIyPjmseorKzEn3/+ibvuugsODg6m7XK5HA8++CAuXbrU7KEHLVFQUIDHH38cAQEBUCgUUCqVCAoKAlA3RvJqV7dZbGwsAOCee+5psP2uu+6CQtHwC7Jff/0VN998M3x9fVFbW2u6TZo0qUGs1nj44Ychk8ka9NStXbsW9vb2uPfee03b9uzZg1tvvRXOzs6Qy+VQKpV49dVXUVRU1GimjYiICPTs2bNZx//hhx8watQoODg4mM7jl19+2eQ5nDBhgmk8OVDXxvfeey8uXLiAS5cuNRn/woULSEpKwuzZswGgwfmbPHkycnNzr/v+yMnJAQB4eno2euzpp59GQUEBfvjhBwCA0WjEmjVrMGXKlDYNSbnatc7nqVOncOedd8Ld3d3UJg899BAMBgPOnz9/w7g333wzHB0dTfe9vLzg6enZ5OfN09MTBQUFpmEqRB2NxStRO6isrERRURF8fX2vuU9oaCh+//13eHp6YsGCBQgNDUVoaCg++OCDFh2r/qvF5vD29r7mtqKiohYdt6WKioqazLX+HF19/KsvGqr/Wl+r1V7zGCUlJRBFsUXHaSuj0YiJEydiy5YteOGFF/DHH3/gr7/+wtGjR6+Z79X51ef092IMqLtA5urzkJ+fj19++QVKpbLBrV+/fgDQaJxtSwQFBWHChAnYsGEDdDodCgsL8euvv+Luu+82FTZ//fUXJk6cCKBu+qxDhw7h2LFjWLp0aZOvt7nvzy1btuCee+6Bn58fvvvuOxw5cgTHjh3DI4880uR40da8l/Pz8wEAixcvbnT+nnjiCQDXP3/1r62pIQADBgzAmDFj8J///AdA3R8Z6enpzZrSqyWaOp+ZmZkYM2YMsrOz8cEHH+DAgQM4duyYKZfrfWbqXf0+A+o+c00919bWFqIoNmscL1F74JhXonawfft2GAwGjB8//rr7jRkzBmPGjIHBYMDx48fx0Ucf4ZlnnoGXlxfuu+++Zh2rJXPH5uXlXXNb/S+v+l/MOp2uwX5tKYrq4+fm5jbaXt+b5eHh0ab4AODq6gqZTNbux/m7s2fPIi4uDl9//TXmzJlj2n7hwoVrPufqNqs/9/n5+fDz8zNtr62tbVSIeXh4ICIiAsuXL28y9vX+YGqOefPmISYmBj///DNycnJQU1ODefPmmR7ftGkTlEolfv311wZFXFNz5ALNf39+9913CA4OxubNmxs85+r3Yb3mvJevVt/2L774ImbOnNnkPr169bpmjvXPLy4ubvLxp556CnfffTdOnjyJ1atXo2fPng0u7DKHps7nTz/9hMrKSmzZssXU4w/UjXFvD8XFxVCpVA2+3SDqSCxeicwsMzMTixcvhrOzM+bPn9+s58jlcgwbNgy9e/fG+vXrcfLkSdx3333N6m1siYSEBMTFxTUYOrBhwwY4Ojpi4MCBAGD6ivPMmTMNfpFv27atUbxr9cw0ZcKECdi6dStycnIaFFjffPMN7OzszDK1lr29PYYNG4YtW7bg3//+t2kKIaPRiO+++w7+/v7N/gq7ueqLiasv+Pr7TBM3MnbsWADA5s2bTe0AAD/++GOjr2bvuOMO7NixA6GhoXB1db1mzNa+d6ZPnw53d3d89dVXyM3NRc+ePTF69GjT44IgQKFQNLhoTqvV4ttvv23Rca4mCAJsbGwaFGd5eXnXnG3gjz/+QH5+vqm32mAwYPPmzQgNDb3mNHG9evVCWFgY4uLisGLFihbnGBQUBLVajdTU1CYfnzFjBgIDA/Hcc88hNjYW7733XosXJmlNuzX1HhRFEZ9//nmLjt1cFy9ebDSFHFFHYvFK1AZnz541jZkrKCjAgQMHsHbtWsjlcmzduvW6V3d/8skn2LNnD6ZMmYLAwEBUV1ebxhreeuutAABHR0cEBQXh559/xoQJE+Dm5gYPD49Wj6Hz9fXFnXfeiejoaPj4+OC7775DTEwM3nrrLdOcjUOGDEGvXr2wePFi1NbWwtXVFVu3bsXBgwcbxevfvz+2bNmCNWvWYNCgQZDJZNec+/S1114zjdd89dVX4ebmhvXr12P79u14++234ezs3KrXdLWVK1ciKioKN998MxYvXgwbGxt8/PHHOHv2LDZu3NjiYuJGevfujdDQUPzf//0fRFGEm5sbfvnlF8TExDQ7Rr9+/XD//ffj3XffhVwuxy233IKEhAS8++67cHZ2bnBl++uvv46YmBiMHDkSTz31FHr16oXq6mqkp6djx44d+OSTT+Dv79/q945KpcLs2bPx0UcfQRRFvPnmmw0enzJlClatWoVZs2bhscceQ1FREf7973+3abYGAKYpoJ544gncddddyMrKwr/+9S/4+PggJSWl0f4eHh645ZZb8Morr5hmG0hKSrrhFE6ffvopJk2ahNtuuw1z586Fn58fiouLkZiYiJMnT5rGrDbFxsYGI0aMMA0JuZpcLseCBQuwZMkS2Nvbt2oFsf79+wOoW/Vszpw5UCqV6NWrV4PxqFeLioqCjY0N7r//frzwwguorq7GmjVrUFJS0uLj34jRaMRff/3VoDeeqMNJebUYkbWqv+K8/mZjYyN6enqK48aNE1esWCEWFBQ0es7VMwAcOXJEnDFjhhgUFCSqVCrR3d1dHDdunLht27YGz/v999/FAQMGiCqVqsGV5/XxLl++fMNjieL/Vtj68ccfxX79+ok2NjZi9+7dxVWrVjV6/vnz58WJEyeKTk5OYrdu3cQnn3xS3L59e6Mrt4uLi8W77rpLdHFxEQVBaHBMNHGle3x8vDh16lTR2dlZtLGxESMjI8W1a9c22Kf+CvEffvihwfb62QGu3r8pBw4cEG+55RbR3t5eVKvV4vDhw8VffvmlyXjmmG3g3LlzYlRUlOjo6Ci6urqKd999t5iZmdnoHFyvzaqrq8VFixaJnp6eoq2trTh8+HDxyJEjorOzs/jss8822Pfy5cviU089JQYHB4tKpVJ0c3MTBw0aJC5dulSsqKgw7Xet986NxMXFiQBEuVwu5uTkNHr8q6++Env16iWqVCoxJCREXLlypfjll182ukr+equ6NTXbwJtvvil2795dVKlUYp8+fcTPP/+8yfcyrqyw9fHHH4uhoaGiUqkUe/fuLa5fv77BftdaYSsuLk685557RE9PT1GpVIre3t7iLbfcIn7yySc3PDdffvnlNc+LKIpienq6CEB8/PHHbxjrWl588UXR19dXlMlkDfK/3vn85ZdfxMjISNHW1lb08/MTn3/+eXHnzp2NXv+1ZhtoasWyptrojz/+EAGIJ06caPXrI2orQRRvcEk0ERFJ4vDhwxg1ahTWr1+PWbNmSZ0OoW4xhfqhAUuWLGn0+EcffYSnnnoKZ8+eNV1E15k8+OCDuHjxIg4dOiR1KtSFsXglIrIAMTExOHLkCAYNGgS1Wo24uDi8+eabcHZ2xpkzZ5o1yT11jDVr1iA6OhoXL140LRJw6tQppKWlYf78+Rg1atQ1L2CzZqmpqejTpw/27NnTYBw0UUfjmFciIgvg5OSE3bt34/3330d5eTk8PDwwadIkrFy5koWrhXnsscdQWlqKixcvmsaozpgxA3l5eRgzZgw++eSTRs8xGo0wGo3XjXv1nL6WJjMzE6tXr2bhSpJjzysREVE7i46OxrJly667T1pamlkXNCDqrFi8EhERtbOcnBzTXMPXEhERARsbmw7KiMh6sXglIiIiIqvB5WGJiIiIyGpY9uhwMzAajcjJyYGjo6PZJycnIiIiorYTRRHl5eXw9fVtsDBLUzp98ZqTk4OAgACp0yAiIiKiG8jKyrrmEs/1On3xWr+kXlZWFpycnCTOpnPT6/XYvXs3Jk6cCKVSKXU61AHY5l0P27xrYrt3PR3d5hqNBgEBAdddCrlepy9e64cKODk5sXhtZ3q9HnZ2dnBycuIPty6Cbd71sM27JrZ71yNVmzdniCcv2CIiIiIiq8HilYiIiIisBotXIiIiIrIaLF6JiIiIyGqweCUiIiIiq8HilYiIiIisBotXIiIiIrIaLF6JiIiIyGqweCUiIiIiq8HilYiIiIisBotXIiIiIrIaLF6JiIiIyGqweCUiIiIiq8HilYiIiIishkLqBIio42VmZqKwsLDNcYxGoxmyISIiaj4Wr0RdTGZmJnr36QNtVVWbY6nVamzcuBGXLl1CcHCwGbIjIiK6PhavRF1MYWEhtFVVmL3kHXgFhrYpVlF2Wt2/RUUsXomIqEOweCXqorwCQ+Ef1q9NMeSCmZIhIiJqJl6wRURERERWg8UrEREREVkNFq9EREREZDVYvBIRERGR1WDxSkRERERWg8UrEREREVkNFq9EREREZDVYvBIRERGR1WDxSkRERERWg8UrEREREVkNFq9EREREZDUspnhduXIlBEHAM888Y9omiiKio6Ph6+sLtVqN8ePHIyEhQbokiYiIiEhSFlG8Hjt2DJ999hkiIiIabH/77bexatUqrF69GseOHYO3tzeioqJQXl4uUaZEREREJCXJi9eKigrMnj0bn3/+OVxdXU3bRVHE+++/j6VLl2LmzJkIDw/HunXrUFVVhQ0bNkiYMRERERFJRSF1AgsWLMCUKVNw66234o033jBtT0tLQ15eHiZOnGjaplKpMG7cOBw+fBjz589vMp5Op4NOpzPd12g0AAC9Xg+9Xt9Or4IAmM4vz7NlMxqNUKvVkAuAIBraFEsu/C+mpbX7pUuXUFRU1OY47u7u8Pf3N0NGnQM/510T273r6eg2b8lxJC1eN23ahJMnT+LYsWONHsvLywMAeHl5Ndju5eWFjIyMa8ZcuXIlli1b1mj77t27YWdn18aMqTliYmKkToFuYOPGjXX/0Z5vU5xgn7ovb3Jzc5Gbm9vWtCxSdnY2zpw5I3UaFoef866J7d71dFSbV1VVNXtfyYrXrKwsPP3009i9ezdsbW2vuZ8gCA3ui6LYaNvfvfjii1i0aJHpvkajQUBAACZOnAgnJ6e2J07XpNfrERMTg6ioKCiVSqnToWuIi4vD2LFjsfDd9fAN7d2mWPkXkzDcRwYfHx8MGDDATBm2Xf1rvOfZN+DpH9zqOAWX0vD9ey9j//79iIyMNGOG1ouf866J7d71dHSb139T3hySFa8nTpxAQUEBBg0aZNpmMBiwf/9+rF69GsnJyQDqemB9fHxM+xQUFDTqjf07lUoFlUrVaLtSqeQHroPwXFs2mUwGrVYLgwiIgrxNsQzi/2JaUpvXv0Z3v2D49OjX6jgGEdBqtRb3+iwBP+ddE9u96+moNm/JMSS7YGvChAmIj4/H6dOnTbfBgwdj9uzZOH36NEJCQuDt7d2gu7qmpgaxsbEYOXKkVGkTERERkYQk63l1dHREeHh4g2329vZwd3c3bX/mmWewYsUKhIWFISwsDCtWrICdnR1mzZolRcpEREREJDHJZxu4nhdeeAFarRZPPPEESkpKMGzYMOzevRuOjo5Sp0ZEREREErCo4nXfvn0N7guCgOjoaERHR0uSDxERERFZFosqXonIOiUnJ0Mma/sQep1O1+QFly2VmJjY5hhERGSZWLwSUauVlxQCvp745z//Ca1Wa4aIAgDRDHHqVFRUmC0WERFZBhavRNRq2spyAJ647ZHFCOnbtnleE/+Kxc51H2DK/KXoFTHoxk9oRqzq6uo2xSEiIsvD4pWI2szNOxD+Ya2fTxUA8jNTAQDuvkFmi0VERJ2PZPO8EhERERG1FItXIiIiIrIaLF6JiIiIyGqweCUiIiIiq8HilYiIiIisBotXIiIiIrIaLF6JiIiIyGqweCUiIiIiq8HilYiIiIisBotXIiIiIrIaLF6JiIiIyGqweCUiIiIiq8HilYiIiIisBotXIiIiIrIaLF6JiIiIyGqweCUiIiIiq8HilYiIiIisBotXIiIiIrIaLF6JiIiIyGqweCUiIiIiq8HilYiIiIisBotXIiIiIrIaLF6JiIiIyGqweCUiIiIiq8HilYiIiIisBotXIiIiIrIaLF6JiIiIyGqweCUiIiIiqyFp8bpmzRpERETAyckJTk5OGDFiBHbu3Gl6fO7cuRAEocFt+PDhEmZMRERERFJSSHlwf39/vPnmm+jRowcAYN26dZg2bRpOnTqFfv36AQBuv/12rF271vQcGxsbSXIlohsTRRGFFTXILtUit0yLy+U61BpFiCIgEwB3BxW8nWzh42wLf1c1BEGQOmUiIrIykhavU6dObXB/+fLlWLNmDY4ePWoqXlUqFby9vaVIj4iaySACCTllOHOpDAXlumvup6muRVphJQDAWa3ETQEu6OvjBBsFRzAREVHzSFq8/p3BYMAPP/yAyspKjBgxwrR937598PT0hIuLC8aNG4fly5fD09PzmnF0Oh10uv/98tRoNAAAvV4PvV7ffi+ATOeX59myGY1GqNVqyAVAEA1tiiUXBBy/LOBwlSdqEgvqtskEBLjawsfJFl5OKtgqZRAgoNZoREF5DfI01Ugv0qJMq0fs+cs4erEI48PcIZfJoFaroZAJbc5LITdPLLkAqNVqGI1Gvq+v4Oe8a2K7dz0d3eYtOY4giqLYjrncUHx8PEaMGIHq6mo4ODhgw4YNmDx5MgBg8+bNcHBwQFBQENLS0vDKK6+gtrYWJ06cgEqlajJedHQ0li1b1mj7hg0bYGdn166vhagrydcC31+U4YKmrtfUTSVilJcRwz1FOCiv/1ydATh2WUBsrgwF1XVDB8JdjbgnxAhnjgwiIupyqqqqMGvWLJSVlcHJyem6+0pevNbU1CAzMxOlpaX473//iy+++AKxsbHo27dvo31zc3MRFBSETZs2YebMmU3Ga6rnNSAgAIWFhTc8GdQ2er0eMTExiIqKglJ5g+qFJBMXF4exY8di4bvr4Rvau1UxkvMrEJN4GbVGEUqZiO7KCtw2IgIKWcvGsBqMIk5kluJoWgmMImCsKsMwdz1GjRjaqrzqnY7die/fexn3v/Qh+g8d1eo4OalJWP3cbOzfvx+RkZFtyqmz4Oe8a2K7dz0d3eYajQYeHh7NKl4lHzZgY2NjumBr8ODBOHbsGD744AN8+umnjfb18fFBUFAQUlJSrhlPpVI12SurVCr5gesgPNeWTSaTQavVwiACoiBv0XMNRhGHLhTiVFYpAMAFlXgqUoVDKRWQyxVo6V/CMjkwJNgDwd0c8dOf51Fp54wTWiN8i6rR3cO+hdH+p9ZghFarrbtYrIWv8e8MIqDVaiGTyfievgo/510T273r6ag2b8kxLO4qCVEUG/Sc/l1RURGysrLg4+PTwVkRkd5gxLa4HFPhOqS7KyJll+Bu2/bYHg4q9EcGtGknYYQM287kIDFX0/bARETU6UhavL700ks4cOAA0tPTER8fj6VLl2Lfvn2YPXs2KioqsHjxYhw5cgTp6enYt28fpk6dCg8PD8yYMUPKtIm6HF2tAT+dykZmcRWUcgF3RPhgZKgHzDnTlQJGFPz4OjzlVRBFIOZcPi4WVpjvAERE1ClIOmwgPz8fDz74IHJzc+Hs7IyIiAjs2rULUVFR0Gq1iI+PxzfffIPS0lL4+Pjg5ptvxubNm+Ho6Chl2kRdilZfV7gWlOtgo5Bh+k2+8HFWt8/BjLXobVMKDxdvnMvVYGd8Hv4x0B/ezmbo3iUiok5B0uL1yy+/vOZjarUav/32WwdmQ0RXq6k14ufTdYWrWinH9AG+8HRs30JSEIBbenuisqYWGUVV2BaXg7sH+8PVjtMQEBGRBY55JSLLYDCK2B6fi3yNDrZKGf4x0K/dC9d6cpmAyeE+8HRUQas3YPuZXOgNxg45NhERWTYWr0TUiCiK2H0uD5nFVVDIBEyL9IO7Q9NzK7cXG4UMd0b6ws5GjqLKGsSev9yhxyciIsvE4pWIGjlysQjn8ysgE4A7InwkG3Nqr1Lgtn51y0Mn5GiQnFcuSR5ERGQ5WLwSUQMp+eU4ll4CALi1jxeC3Fs/36o5BLrZYWh3NwDAH0n5KK2qkTQfIiKSFotXIjK5XK7D7nP5AICBgS7o42MZq9INC3aDr4st9AYRvycWQOKFAYmISEIsXokIAFCtN+DXMzmoNYoIdLPDqFAPqVMykckE3NbXGwqZgOxSLRJyuIABEVFXxeKViCCKImLO5UNTXQtntRKTwr0hk5lxBQIzcFIrMSLUHQBw8EIhKnW1EmdERERSYPFKRIi7VIaLhZWQCwIm9/eGrVIudUpNusnfBZ6OKuhqjZx9gIioi2LxStTFFWiqcTClEAAwOsyjw+ZybQ2ZTMCEPp4QBCCloALpRZVSp0RERB2MxStRF1ZTa8SOs3kwiCJCu9kj0t9Z6pRuyNPRFjf5uwAADqYUwmjkxVtERF0Ji1eiLuzghUKUafVwUClwax8vCIJljXO9lqHBbrBVyFBUWYOEXF68RUTUlbB4Jeqi8rQC4rPLAAAT+3pZ7DjXptgq5RgaXDf365HUItTUculYIqKugsUrURcks3XAiWIFgLqLoALc7CTOqOUi/F3grFZCqzfgeEax1OkQEVEHYfFK1AW53fo4qg0CXO2UGNnDXep0WkUuEzC6R91ctCczS1FRzamziIi6AhavRF3MsZxq2PcbDwEiJvb1hlJuvT8GQrvZw8fZFgajyN5XIqIuwnp/axFRi2mq9fj0RN041zBHI7ydLXdarOYQBAEjQup6js9ma9j7SkTUBbB4JepC3tyZhGKtEfriHPR1Nkidjln4u6rh62ILgyjiGHtfiYg6PRavRF3EkdQibPgzEwBQtOtDWPFogQYEQcDw4Lre14RsDcqr9RJnRERE7amT/PoiouvR1RqwdGs8AGBiiB10WWclzsi8/t77ejyjROp0iIioHbF4JeoCvjiQhouFlfBwUOHBCEep0zG7q3tfa6CQOCMiImovLF6JOrms4ip8tCcFAPDylD6wt+mcH3t/V3XdzAOiiBy4Sp0OERG1k875W4yITJb9cg7VeiOGh7hh2k2+UqfTbgRBwMDAuqI1F64QbNQSZ0RERO2BxStRJ/ZHYj5+T8yHQibgX9PCIQiC1Cm1q5Bu9nBRK2GAHA4RUVKnQ0RE7YDFK1EnVa03IPqXBADAvDHBCPPqfGNdryb7W++r0+DpMIoSJ0RERGbH4pWok/p47wVkFWvh42yLp24JkzqdDtPHxxFK1ELh7InLBg4dICLqbFi8EnVCaYWV+CT2IgDg1Tv6wl7Vda6+V8hl8EHddFmX9PYQRXa/EhF1JixeiToZURTx6s9nUWMwYlzPbrg93FvqlDqcD0pg1OtQIdogT1MtdTpERGRGLF6JOpnfEvJwIKUQNgoZlt3Zr9NfpNUUJQyoStwPADidVSptMkREZFYsXok6EV2tASt2JAEA5o8NQXcPe4kzkk75yV8BABcKKlCpq5U4GyIiMhcWr0SdyDeHM5BZXAVPRxUeHxcqdTqSqslPhZOsBkYROJtdJnU6RERkJixeiTqJ4soafHhlJa3Ft/XqUhdpXYufohIAEJ9dBgPnzSIi6hRYvBJ1Eh/8fh7l1bXo5+uEuwb6S52ORfCQa2FnI0dljQGplyukToeIiMyAxStRJ3ChoBzf/ZkJAFg6pQ9ksq53kVZTZAIQ7ucMADhziUMHiIg6A0mL1zVr1iAiIgJOTk5wcnLCiBEjsHPnTtPjoigiOjoavr6+UKvVGD9+PBISEiTMmMgyrdiRBINRRFRfL4wM9ZA6HYsS7usEAUB2qRYllTVSp0NERG0kafHq7++PN998E8ePH8fx48dxyy23YNq0aaYC9e2338aqVauwevVqHDt2DN7e3oiKikJ5ebmUaRNZlAMpl7EnqQAKmYAXJ/WWOh2L42irRJC7HQDgbA57X4mIrJ2kxevUqVMxefJk9OzZEz179sTy5cvh4OCAo0ePQhRFvP/++1i6dClmzpyJ8PBwrFu3DlVVVdiwYYOUaRNZDINRxPLtiQCAh0Z0R0g3B4kzskz9rwwdSMwt54VbRERWzmIuRzYYDPjhhx9QWVmJESNGIC0tDXl5eZg4caJpH5VKhXHjxuHw4cOYP39+k3F0Oh10Op3pvkajAQDo9Xro9fr2fRFdXP355XluP5cuXUJRUZHpfszFKiTllcNBKWCMewWOHz9+wxjJyclQq9WQC4AgGtqUj+LK2FqFTGh7LLkMarW6XWIFu9nC/sqFWxcva9DTs3lFvlwA1Go1jEYj39dX8HPeNbHdu56ObvOWHEcQJV74Oz4+HiNGjEB1dTUcHBywYcMGTJ48GYcPH8aoUaOQnZ0NX19f0/6PPfYYMjIy8NtvvzUZLzo6GsuWLWu0fcOGDbCzs2u310HU0aoNwL9OyVGhFzCjuwHjfdijeD3bM2XYnS1DT2cjFvQ1Sp0OERH9TVVVFWbNmoWysjI4OTldd1/Je1579eqF06dPo7S0FP/9738xZ84cxMbGmh6/emlLURSvu9zliy++iEWLFpnuazQaBAQEYOLEiTc8GdQ2er0eMTExiIqKglKplDqdTicuLg5jx47FPc++AU//YJwpqStcHRUi5EYDDuU0L07yiYOI2bAG97/0IfoPHdWmnM4e2IWpg0OwI6EQfQaPbFOs07E78f17L5slr6Zi+QXqgewsnC+T4TSC4Ky+8Xs0JzUJq5+bjf379yMyMrJNOXUW/Jx3TWz3rqej27z+m/LmkLx4tbGxQY8ePQAAgwcPxrFjx/DBBx9gyZIlAIC8vDz4+PiY9i8oKICXl9c146lUKqhUqkbblUolP3AdhOe6fchkMmi1Wrj7BcPerydSsjIAiBjf1xd+LRjrmpORCq1Wi1qjCFGQtymn2ivjR80Sy2A0X15NxHKykyPQzQ6ZxVU4m1vRrFkZDCKg1Wohk8n4nr4KP+ddE9u96+moNm/JMSxunldRFKHT6RAcHAxvb2/ExMSYHqupqUFsbCxGjmxbDw+RtTuUWgiDUYS/qxrBHvZSp2M1+vnWffuSmFsOo7QjpoiIqJUk7Xl96aWXMGnSJAQEBKC8vBybNm3Cvn37sGvXLgiCgGeeeQYrVqxAWFgYwsLCsGLFCtjZ2WHWrFlSpk0kqSKdgPP5datFjQ3rdt1hNNRQiIc9VAoZKnS1uFSiRaAbx8ETEVkbSYvX/Px8PPjgg8jNzYWzszMiIiKwa9cuREVFAQBeeOEFaLVaPPHEEygpKcGwYcOwe/duODo6Spk2kaTOlNR9Dd7XxwndHBsPkaFrU8hl6OnliPjsMpzL1bB4JSKyQpIWr19++eV1HxcEAdHR0YiOju6YhIgsnF3vMSiukUEpFzAy1F3qdKxSXx8nxGeXIbWgArpeBqgUbRtfS0REHcvixrwSUdNqDCJcx88FAAwOcoO9SvLrLa2Sl5MKbnY2qDWKSCmokDodIiJqIRavRFbi1/OVUDh7QS0XMSDQRep0rJYgCOjjWzf0KDGn+VOzEBGRZWDxSmQFLpfr8N/Eul7CcBcDlHJ+dNuit7cTBAA5ZdUoqaqROh0iImoB/gYksgLv/X4e2loRupzzCLDj6lBt5aBSINC97mKt5LxyibMhIqKWYPFKZOGS8jTY9FcmAKBkzxfgzFjm0durbuhAcn45JF4lm4iIWoDFK5EFE0URy7cnwigCI/xtocs+J3VKnUZINwcoZAJKq/QoKNdJnQ4RETUTi1ciC7bv/GUcSCmEjVyGByM4v7E52ShkCLmyOhmHDhARWQ8Wr0QWqtZgxPLtiQCAh0d1h7cDp8Yyt17edX8QnM/ncrFERNaCxSuRhdr4VyYuFFTAzd4GT9zcQ+p0OqUg97rlYitrDMgu0UqdDhERNQO7cqjTyMzMRGFhoVlieXh4IDAw0CyxWqNMq8d7v6cAAJ69NQzOaqVkuXRmcpmAME8HnM3RIDm/HAFcLpaIyOKxeKVOITMzE7379IG2qsos8dR2dkhKTJSsgP147wUUV9agh6cD7h8qXRHdFfTydsTZHA1SCiowvlc3KGT8QoqIyJKxeKVOobCwENqqKsxe8g68AkPbFCs/MxXr33oehYWFkhSvmUVVWHsoHQCwdEofKLggQbvyc1HDQaVAha4W6YVV6OHpIHVKRER0HSxeqVPxCgyFf1g/qdNokzd3JaLGYMSYMA+M79lN6nQ6PUEQ0NPLASczS5GcX87ilYjIwrFLh8iCHEsvxo74PMgE4OUpfSFwRYIOUT/rQFphJXS1BomzISKi62HxSmQhjEYR//q1bhGC+4YGmgoqan/dHFRwtVPCYBSRerlS6nSIiOg6WLwSWYif47Jx5lIZHFQKPHtrT6nT6VIEQTD9scAFC4iILBuLVyILoK0x4O1dyQCABTf3QDdHlcQZdT29vOqK16ziKlTqaiXOhoiIroXFK5EF+OLAReSWVcPPRY2HR3WXOp0uycXOBt5OthABpBRUSJ0OERFdA4tXIonla6qxJjYVAPB/k3rDVimXOKOuq37oQFKeRuJMiIjoWli8Ekns7V3JqKoxYGCgC+6I8JE6nS4tzNMBAoB8jQ5lWr3U6RARURNYvBJJ6MylUvz35CUAwGtT+3FqLInZqxTwc1UDAC5w6AARkUVi8UokEVEU8fovdVNjzRzoh8gAF2kTIgB1va8AcD6fsw4QEVkiFq9EEvnlTC6OZ5RArZTjhdt6S50OXRHarW7oQEG5DpWcdICIyOKweCWSgLbGgDd3JAIAnhgfCm9nW4kzonp/HzpwqYo/IomILA1/MhNJ4LP9F5FzZWqsf44NkTodukr90IFsFq9ERBaHP5mJOlhumRafXJka68XJnBrLEvW4MutASY0MCmcvqdMhIqK/YfFK1MHe3pUMrd6AId1dMaU/p8ayRHY2/xs6YNdrtMTZEBHR37F4JepAJzNLsPVUNgQBePUOTo1lyXp61i1YYNebxSsRkSVh8UrUQYzG/02NdddAf/T3d5Y4I7qeUE97ACJUPmHIq+C0A0REloLFK1EH+TkuG6ezSmFvI8fzt/eSOh26ATsbBbqpRADA4axqibMhIqJ6rSpe09LSzJ0HUadWVVOLt3YmAwAW3NIDno6cGssa+NsbAQCHL2klzoSIiOq1qnjt0aMHbr75Znz33XeormaPBNGNfBJ7EXmaagS4qfHIqGCp06Fm8lMbIRoNuFhSi4yiSqnTISIitLJ4jYuLw4ABA/Dcc8/B29sb8+fPx19//WXu3Ig6hexSLT69MjXWS5P6cGosK6KSA9WZZwAA2+NzJc6GiIiAVhav4eHhWLVqFbKzs7F27Vrk5eVh9OjR6NevH1atWoXLly83K87KlSsxZMgQODo6wtPTE9OnT0dycnKDfebOnQtBEBrchg8f3pq0iSTx5s4k6GqNGBbshtvDvaVOh1qoKukgAGAHi1ciIovQpgu2FAoFZsyYge+//x5vvfUWUlNTsXjxYvj7++Ohhx5Cbu71f9jHxsZiwYIFOHr0KGJiYlBbW4uJEyeisrLh13O33347cnNzTbcdO3a0JW2iDnM8vRi/xOXUTY01tS+nxrJCVeePQCYAZ7M1HDpARGQBFG158vHjx/HVV19h06ZNsLe3x+LFizFv3jzk5OTg1VdfxbRp0647nGDXrl0N7q9duxaenp44ceIExo4da9quUqng7d28HiudTgedTme6r9FoAAB6vR56vb4lL49aqP78SnGejUYj1Go15AIgiIY2xZILgFqthtFobNNrMRpFRG9LAADcPdAPPbvZtTGeeV6jQi6DWq2GQia0+VwpZILp3zbHMmdeZoolFwAV9AjvZoMzBTXYduoSHh/XtZfzlfJzTtJhu3c9Hd3mLTmOIIqi2NIDrFq1CmvXrkVycjImT56MRx99FJMnT4ZM9r+O3AsXLqB3796orW3+/IgXLlxAWFgY4uPjER4eDqBu2MBPP/0EGxsbuLi4YNy4cVi+fDk8PT2bjBEdHY1ly5Y12r5hwwbY2dm18JUStd5fBQLWp8qhkot4+SYDnGykzoha63C+gM0X5fC3F/F8RNsKayIiaqyqqgqzZs1CWVkZnJycrrtvq4rXsLAwPPLII3j44Yev2SNaU1ODjRs3Ys6cOc2KKYoipk2bhpKSEhw4cMC0ffPmzXBwcEBQUBDS0tLwyiuvoLa2FidOnIBKpWoUp6me14CAABQWFt7wZFDb6PV6xMTEICoqCkqlskOPHRcXh7Fjx2Lhu+vhG9q7TbFyUpOw+rnZ2L9/PyIjI1sVo1JXi4kfHEJBuQ4v3BaGf45u+wwD5nqNp2N34vv3Xsb9L32I/kNHtSmnswd2YergEOxIKESfwSPbFMuceZkrVv174deYffjn9kIYjCL+eHY0At267h/CUn7OSTps966no9tco9HAw8OjWcVrq4YNpKSk3HAfGxubZheuALBw4UKcOXMGBw8ebLD93nvvNf0/PDwcgwcPRlBQELZv346ZM2c2iqNSqZosapVKJT9wHUSKcy2TyaDVamEQAVFo29X8BhHQarWQyWStfh2f70lFQbkOQe52mDcmFEpF22cYMNdrrDUYodVqUWsU23yuao2i6d82xzJnXmaKVf9ecFErMDzEDYcuFGF3YiH+3/jQNuXXGfBnatfEdu96OqrNW3KMVl2wtXbtWvzwww+Ntv/www9Yt25di+M9+eST2LZtG/bu3Qt/f//r7uvj44OgoKBmFdBEUsgqrsLnB+oW8nhpch+ozFC4kvQm9/cBAOw8y1kHiIik1Kri9c0334SHh0ej7Z6enlixYkWz44iiiIULF2LLli3Ys2cPgoNv/NVqUVERsrKy4OPj06KciTrKyp2JqKk1YmSoOyb29ZI6HTKT2/p5QyYAZy6VIau4Sup0iIi6rFYVrxkZGU0WmkFBQcjMzGx2nAULFuC7777Dhg0b4OjoiLy8POTl5UGrrVuKsaKiAosXL8aRI0eQnp6Offv2YerUqfDw8MCMGTNakzpRu/rzYhF2xOdBxqmxOh0PBxWGBbsDYO8rEZGUWlW8enp64syZM422x8XFwd3dvdlx1qxZg7KyMowfPx4+Pj6m2+bNmwEAcrkc8fHxmDZtGnr27Ik5c+agZ8+eOHLkCBwdHVuTOlG7MRhFvP7rOQDA/UMD0dubFwh2NpMj6r7x2R6fJ3EmRERdV6su2Lrvvvvw1FNPwdHR0TQfa2xsLJ5++mncd999zY5zo4kO1Go1fvvtt9akSNThfjyRhYQcDRxtFVgU1VPqdKgd3NbPC6/+fBZxWaW4VFIFf9euO+sAEZFUWtXz+sYbb2DYsGGYMGEC1Go11Go1Jk6ciFtuuaVFY16JOovyaj3e+a1uaeOnJ4TB3aHxjBdk/TwdbTG0uxsAYNdZ9r4SEUmhVcWrjY0NNm/ejKSkJKxfvx5btmxBamoqvvrqK9jYcCZ26npW772AwooahHjY46ER3aVOh9pR/awD2+M57pWISAptWh62Z8+e6NmTX49S15ZRVIm1B9MBAEun9IGNolV/E5KVuD3cG9G/JOBUZilySrXwdVFLnRIRUZfSquLVYDDg66+/xh9//IGCggIYjcYGj+/Zs8csyRFZgxU7ElFjMGJMmAdu6d30ssXUeXg52WJwkCuOpZdg59k8zDPD6mlERNR8rSpen376aXz99deYMmUKwsPDOR0QdVmHUwvxW0I+5DIBr9zBqbG6isn9feqK1/hcFq9ERB2sVcXrpk2b8P3332Py5MnmzofIahiMIl7/pW5qrNnDAtHTi9O3dRW3h3tj2S/ncDyjBHll1fB2tpU6JSKiLqPVF2z16NHD3LkQWZVNxzKRlFcOZ7USz97Ksd9diY+zGoOCXAEAu7hgARFRh2pV8frcc8/hgw8+uOE8rUSdlaZaj3d3nwcAPHNrGFztOctGVzMp3BsAsIMLFhARdahWDRs4ePAg9u7di507d6Jfv35QKpUNHt+yZYtZkiOyVB/9kYLiyhqEdrPHA8ODpE6HJDC5vw/e2J6IYxnFKNBUw9OJQweIiDpCq4pXFxcXzJgxw9y5EFmFtMJKfH04HQDw8h19oZRzaqyuyNdFjQGBLjiVWYpdCXmc35eIqIO0qnhdu3atufMgshrLt5+D3iBifK9uuLkXp8bqyiaH++BUZim2n8ll8UpE1EFa3WVUW1uL33//HZ9++inKy8sBADk5OaioqDBbckSW5kDKZfyeWACFTMDLU/pKnQ5JbFL/unGvf6UX43K5TuJsiIi6hlYVrxkZGejfvz+mTZuGBQsW4PLlywCAt99+G4sXLzZrgkSWotZgxL9+rZsa68ERQejh6SBxRiQ1f1c7RPo7QxSBXQm8cIuIqCO0qnh9+umnMXjwYJSUlECt/t/SiDNmzMAff/xhtuSILMnGvzJxPr8CLnZKPD0hTOp0yEJM7u8DANgZzymziIg6QquK14MHD+Lll1+GjU3D6YGCgoKQnZ1tlsSILElZlR6rYuqmxloU1RMudpwai+rUF69HLxahsIJDB4iI2lurilej0QiDwdBo+6VLl+DoyFWGqPN5/4/zKKnSo6eXA2YNDZQ6HbIgAW526O/nDKMI/MahA0RE7a5VxWtUVBTef/99031BEFBRUYHXXnuNS8ZSp3OhoALfHskAALxyR18oODUWXaX+wq2dXLCAiKjdteq38HvvvYfY2Fj07dsX1dXVmDVrFrp3747s7Gy89dZb5s6RSFJvbD+HWqOICb09MSasm9TpkAWaHF43dODIxSIUV9ZInA0RUefWqnlefX19cfr0aWzcuBEnT56E0WjEvHnzMHv27AYXcBFZs8TERJzMrca+5BIoZMCMYBEnT55scRwPDw8EBnKoQWfW3cMefX2ccC5Xg90JebiPQ0uIiNpNq4pXAFCr1XjkkUfwyCOPmDMfIslpiuumfnvgwYfg88hq2HgEovjoVkxd+WWr4qnt7JCUmMgCtpObEuGDc7kabI/PZfFKRNSOWlW8fvPNN9d9/KGHHmpVMkSWQFuhAQAMX/g+cu0CYSMTMXvmFNjcNaXFsfIzU7H+redRWFjI4rWTmxTujXd+S8bh1CKUVNbA1Z4zUhARtYdWFa9PP/10g/t6vR5VVVWwsbGBnZ0di1eyejKVPS7bdQcAjAzzRIi/i6T5kOUL6eaA3t6OSMorR8y5fNwzJEDqlIiIOqVWXbBVUlLS4FZRUYHk5GSMHj0aGzduNHeORB3OedT9qIUMbvY26O/rLHU6ZCWmXJnzdTsXLCAiajdmm/MnLCwMb775ZqNeWSJro4USjgPrhgiMDfOATCZInBFZi0lXitdDFwpRVqWXOBsios7JrBNWyuVy5OTkmDMkUYdLgxcEuRJusmoEudtLnQ5ZkR6eDujl5Yhao4jd5zjnKxFRe2jVmNdt27Y1uC+KInJzc7F69WqMGjXKLIkRSSGruArFcIRoNCDEViN1OmSFJvX3RnJ+OXaezcPdgznulYjI3FpVvE6fPr3BfUEQ0K1bN9xyyy149913zZEXUYcziiL2p9RNk1V+aifsxwyUOCOyRlP6++D931NwIOUyyqr0cLZTSp0SEVGn0qri1Wg0mjsPIsmdy9WgsKIGchhQdmgDwOKVWiHMyxG9vByRnF+OXQm5uHcIp0gjIjInLtJOBKCm1ogjqUUAgEAUwqjlkAFqvTtv8gUAbIvjNQBERObWqp7XRYsWNXvfVatWteYQRB3qeEYxqmoMcFEr4aMtljodsnJTI3zxzm/JOJJahILyang62kqdEhFRp9Gq4vXUqVM4efIkamtr0atXLwDA+fPnIZfLMXDg/75qFQROMUSWT6PV42RmKQBgdJgHSs9Imw9Zv0B3O9wU4ILTWaXYfiYXD48KljolIqJOo1XF69SpU+Ho6Ih169bB1dUVQN3CBQ8//DDGjBmD5557zqxJErWnQxcKYTCK8HdVI8TDHielTog6hTsjfXE6qxTb4nJYvBIRmVGrxry+++67WLlypalwBQBXV1e88cYbLZptYOXKlRgyZAgcHR3h6emJ6dOnIzk5ucE+oigiOjoavr6+UKvVGD9+PBISElqTNlEjOaVanC+oAACMDevGbwvIbO6I8IFMAE5lliKruErqdIiIOo1WFa8ajQb5+fmNthcUFKC8vLzZcWJjY7FgwQIcPXoUMTExqK2txcSJE1FZWWna5+2338aqVauwevVqHDt2DN7e3oiKimrRcYiaIv5taqx+vk7o5qiSOCPqTDydbDE8xB0A8MsZXrhFRGQurSpeZ8yYgYcffhg//vgjLl26hEuXLuHHH3/EvHnzMHPmzGbH2bVrF+bOnYt+/fohMjISa9euRWZmJk6cOAGgrrh4//33sXTpUsycORPh4eFYt24dqqqqsGHDhtakTmRyPr8C+RodlHIBI64UGUTmdGfklVkHTrN4JSIyl1aNef3kk0+wePFiPPDAA9Dr69bvVigUmDdvHt55551WJ1NWVgYAcHNzAwCkpaUhLy8PEydONO2jUqkwbtw4HD58GPPnz28UQ6fTQafTme5rNHVTHun1elOu1D7qz68U59loNEKtVkMuAIJouOH+tUYRh1MLAQBDglzgYCMAV56nkMugVquhkAnNinU9cgFQq9VITExs8/zIycnJLXqN12LO16eQCaZ/2xzLnHmZKVZ9+xmNxla9ryf08oBSLiAprxznsksQ5unQ6lwshZSfc5IO273r6eg2b8lxBFEUxdYeqLKyEqmpqRBFET169IC9fevXgRdFEdOmTUNJSQkOHDgAADh8+DBGjRqF7Oxs+Pr6mvZ97LHHkJGRgd9++61RnOjoaCxbtqzR9g0bNsDOzq7V+VHnsidHwM8ZcjjbiHj5JgNs5FJnRJ3VZ0kyJJTIMNHPiCmBXOCFiKgpVVVVmDVrFsrKyuDk5HTdfVvV81ovNzcXubm5GDt2LNRqNURRbPUFLwsXLsSZM2dw8ODBRo9dHfN6x3nxxRcbzEOr0WgQEBCAiRMn3vBkUNvo9XrExMQgKioKSmXHLokZFxeHsWPHYuG76+Eb2vu6+1brDdiVnQXAiKEhnsh2cGzw+OnYnfj+vZdx/0sfov/QUW3Kqz7WbY8sRli/AW2KlXziIGI2rGlzXuZ8fWcP7MLUwSHYkVCIPoNHtilWe5z3tsbKSU3C6udmY//+/YiMjGxVjFq/XDz3YzyStPZYPWm01V8UKOXnnKTDdu96OrrN678pb45WFa9FRUW45557sHfvXgiCgJSUFISEhODRRx+Fi4tLi2YcAIAnn3wS27Ztw/79++Hv72/a7u3tDQDIy8uDj4+PaXtBQQG8vLyajKVSqaBSNb7wRqlU8gPXQaQ41zKZDFqtFgYREIXrd6P+mVEMXa0R7g426O3rDPGqYqLWYIRWq0WtUbxhrBupj+XkGQCfHv3aFCsnI9UseZn19RlF07/mOleWFMsgAlqtFjKZrNXv6dv7+2LpzwnILNYiMb8KkQEurc7HkvBnatfEdu96OqrNW3KMVl2w9eyzz0KpVCIzM7PBV/H33nsvdu3a1ew4oihi4cKF2LJlC/bs2YPg4IZzIQYHB8Pb2xsxMTGmbTU1NYiNjcXIkW3r5aGuqUyrx5msurHVY3p4QGblvWBk+exVCtzap+6PbS4XS0TUdq0qXnfv3o233nqrQS8pAISFhSEjI6PZcRYsWIDvvvsOGzZsgKOjI/Ly8pCXlwetVgugbrjAM888gxUrVmDr1q04e/Ys5s6dCzs7O8yaNas1qVMXdzi1EAZRRKCbHYLcWz9Gm6gl6mcd+PVMDozGVl9mQEREaOWwgcrKyiYvfiosLGzyK/trWbNmDQBg/PjxDbavXbsWc+fOBQC88MIL0Gq1eOKJJ1BSUoJhw4Zh9+7dcHR0BFFL5GmqcT6/bkGC0T08JM6GupJxvbrByVaBfI0Of6UXm+Z/JSKilmtVz+vYsWPxzTffmO4LggCj0Yh33nkHN998c7PjiKLY5K2+cK2PHR0djdzcXFRXVyM2Nhbh4eGtSZu6MFEUcTClbmqsPj6OXJCAOpRKIcft4XVj+H/mnK9ERG3Sqp7Xd955B+PHj8fx48dRU1ODF154AQkJCSguLsahQ4fMnSNRm6UVViK7VAu5jAsSkDSm3+SH749fwvYzOXhtal/YKjk/GxFRa7Sq57Vv3744c+YMhg4diqioKFRWVmLmzJk4deoUQkNDzZ0jUZsYjCIOXqjrdR0Q4AJHW14pSx1veIg7fJxtoamuxd6kAqnTISKyWi3uedXr9Zg4cSI+/fTTJhcDILI0CTllKKnSQ62UY3B3V6nToS5KJhMwfYAf1uxLxX9PZmNSf58bP4mIiBppcc+rUqnE2bNnrX6ibeoaamqNOHqxGAAwNNgNKgW/qiXpzBzgBwDYl1yAogrdDfYmIqKmtGrYwEMPPYQvv/zS3LkQmd2JjBJo9QY4q5Xo7+csdTrUxYV5OaK/nzNqjSJ+PZMrdTpERFapVRds1dTU4IsvvkBMTAwGDx4Me/uG82WuWrXKLMkRtUVFdS1OZpYAAEb1cIdcxm8LSHozBvghPrsMW05ewpyR3aVOh4jI6rSoeL148SK6d++Os2fPYuDAgQCA8+fPN9iHwwnIUhxNK0KtUYSPsy16dHOQOh0iAMCdN/li+Y5ExF0qw4WCCvTw5HuTiKglWlS8hoWFITc3F3v37gVQtxzshx9+CC8vr3ZJjqi1iitrcC5HA6BuQQL+UUWWwsNBhXE9u2FPUgH+e/ISltzeW+qUiIisSovGvIpiw2UNd+7cicrKSrMmRGQOh1MLIQII8bCHr4ta6nSIGrhrUN3S2ltOXkKtwShxNkRE1qVVF2zVu7qYJbIEuWVapF6uhABgZCgXJCDLM6GPJ1ztlMjX6HDgyspvRETUPC0aNiAIQqOvX/l1LFkSUQQOXSgCAPTxcYK7A5eBpbZLTEw0SxwPDw8EBgZCpZBj+gA/rD2Uju+PZ+Hm3p5miU9E1BW0qHgVRRFz586FSlVXEFRXV+Pxxx9vNNvAli1bzJchUQvkVwumZWCHhbhJnQ5ZOU3xZQDAAw88YJZ4ajs7JCUmIjAwEHcPCsDaQ+n4PTEfxZU1cLO3McsxiIg6uxYVr3PmzGlw31w/0InMQ8DZ0rpFCCL8neHEZWCpjbQVdRf9TZm/FL0iBrUpVn5mKta/9TwKCwsRGBiIvr5O6O/njPjsMvx0KhuPjA42R8pERJ1ei4rXtWvXtlceRG1m12csyvQy2MhlGNKdva5kPu6+QfAP62f2uPcM9kd8dhm+P56Fh0d15zAsIqJmaNMFW0SWQm8Q4TKm7puAQUGuUCu5DCxZvjsj/WCjkCEprxzx2WVSp0NEZBVYvFKnEHOxCkpXH9jKRAwIdJE6HaJmcbZT4vZ+3gCAjX9lSZwNEZF1YPFKVq9SV4sfzlUAAHo7G6CU821N1uP+oYEAgG2ns1Ghq5U4GyIiy8ff8mT1vjiQhjKdEfriHAQ7cMJ3si7DQ9wQ0s0elTUG/Hw6W+p0iIgsHotXsmpFFTp8tj8VAFB64FvIeL0LWRlBEDDrSu/rhj8zufgLEdENsHglq/afvamorDEg2EWBqqSDUqdD1Cr/GOgPG4UMCTkanLnEC7eIiK6HxStZrUslVfjuaAYA4MEIJwDssSLr5Gpvg8nh9RduZUqcDRGRZWPxSlZrVcx51BiMGBnqjkgvrk5E1q3+wq2fT+dAU62XOBsiIsvF4pWsUlKeBltP1V3csuT23pzcnaze0GA3hHk6QKs34L8nLkmdDhGRxWLxSlbpnV3JEEVgcn9vRAa4SJ0OUZsJgoCHRgQBAL45kgGjkcNgiIiawuKVrM6x9GL8kVQAuUzA4om9pE6HyGxmDvSHo0qBtMJK7E+5LHU6REQWicUrWRVRFPHWziQAwD2DAxDSzUHijIjMx16lwF2D/QEA6w6nS5sMEZGFYvFKVuWPxAIczyiBSiHD0xPCpE6HyOweGtEdALDv/GWkF1ZKmwwRkQVi8UpWw2AU8fZvdb2uD48KhrezrcQZEZlfsIc9xvfqBlGsG/tKREQNsXglq7H1VDbO51fAyVaB/zcuVOp0iNrNnJHdAQA/HM9COafNIiJqgMUrWYVqvQHvxZwHADxxcw842yklzoio/YwL64aQbvYo19Vi87EsqdMhIrIoLF7JKnx3NAPZpVp4O9li7pVeKaLOSiYT8M8xIQCAtYfSoTcYJc6IiMhysHgli1dercd/9l4AADxzaxhslXKJMyJqfzMG+MHDwQbZpVrsiM+VOh0iIovB4pUs3uf7L6KkSo+Qbva4a5C/1OkQdQhbpdw088Bn+y9CFLloARERIHHxun//fkydOhW+vr4QBAE//fRTg8fnzp0LQRAa3IYPHy5NsiSJy+U6fHEwDQDw/MReUMj59xZ1HQ8MD4KtUoaEHA2OpBZJnQ4RkUWQtBKorKxEZGQkVq9efc19br/9duTm5ppuO3bs6MAMSWof7UlBVY0BkQEuuD3cW+p0iDqUm70N7hkcAAD4ZP9FibMhIrIMCikPPmnSJEyaNOm6+6hUKnh7s2jpijKKKrHhz0wAwJLbe0EQBIkzIup480YH47ujGdh//jLOXCpFhL+L1CkREUlK0uK1Ofbt2wdPT0+4uLhg3LhxWL58OTw9Pa+5v06ng06nM93XaDQAAL1eD72e8yW2p/rza67z/M6uJNQaRYzp4Y4hgc7XjWs0GqFWqyEXAEE0tOm4CrkMarUaCpnQKWOZNSeZYPrXUl6fOWOZMye5AKjVahiNxhZ9RnydbDA1wgc/x+Xioz9S8PGsm9qUR1uZ+3NO1oHtbj0uXbqEoqK2DzMyGutmOemoNm/JcQTRQq4CEAQBW7duxfTp003bNm/eDAcHBwQFBSEtLQ2vvPIKamtrceLECahUqibjREdHY9myZY22b9iwAXZ2du2VPpnZpUrgnTN1f1s9H1ELf3uJEyKSUL4WWHlaDhECXoiohR8/D0TUyVRVVWHWrFkoKyuDk5PTdfe16OL1arm5uQgKCsKmTZswc+bMJvdpquc1ICAAhYWFNzwZ1DZ6vR4xMTGIioqCUtm2RQTmfXMC+1OKcEd/b7x3T8QN94+Li8PYsWOx8N318A3t3aZjn47die/fexn3v/Qh+g8d1elimTOnswd2YergEOxIKESfwSPbFKuzn6uc1CSsfm429u/fj8jIyBY//+nNcdhxNh+Tw73wwb0tf765mPNzTtaD7W4d6n8X3vPsG/D0D25TrOKcdEwdHAIfHx8MGDDATBlem0ajgYeHR7OKV4sfNvB3Pj4+CAoKQkpKyjX3UalUTfbKKpVKfuA6SFvP9eELhdifUgSlXMDzt/duViyZTAatVguDCIhC2+aBrTUYodVqUWsUO2Uss+ZkFE3/WsrrM2csc+ZkEAGtVguZTNaqz8eTE3pix9l87EzIx6KSavTwdGxTPm3Fn6ldE9vdstX/LnT3C4ZPj35mi9kRbd6SY1jVvENFRUXIysqCj4+P1KlQOzEaRazcmQQAmD0sCEHu/H6UCAD6+Dghqq8XRBH4aM8FqdMhIpKMpMVrRUUFTp8+jdOnTwMA0tLScPr0aWRmZqKiogKLFy/GkSNHkJ6ejn379mHq1Knw8PDAjBkzpEyb2tGOs7mIzy6DvY0cC2/pIXU6RBbl6QlhAIBtcTlIytNInA0RkTQkLV6PHz+OAQMGmMZSLFq0CAMGDMCrr74KuVyO+Ph4TJs2DT179sScOXPQs2dPHDlyBI6O0n5dRu2jptaId35LBgA8NjYUHg5NX5RH1FWF+zljSn8fiCLw79/OS50OEZEkJB3zOn78+Osuefjbb791YDYktU3HMpFRVAUPBxUeHdO2geZEndWzUT2x82wufk/Mx4mMEgwKcpU6JSKiDmVVY16p86rQ1eLDP+ouxHv61jDYq6zqWkKiDtPD0wF3DfIHALzzW9J1OwCIiDojFq9kET7ffxGFFTUI9rDHfUMCpE6HyKI9fWtP2MhlOHqxGAdSCqVOh4ioQ7F4JcldLtfh8wN167Y/f1svKOV8WxJdj5+LGg8MDwIALN+eiFqDUeKMiIg6DqsEktxHe1JQVWNAZIALJoV7S50OkVV4akIPOKuVSM4vx+bjWVKnQ0TUYVi8kqTSCiux4c9MAMD/3d4bgiBInBGRdXCxs8Gzt9ZNnfXu7vMo03LNeSLqGli8kqT+vTsZtUYRN/fqhhGh7lKnQ2RVZg8PQg9PBxRX1mD1nmuvPEhE1JmweCXJxGWVYvuZXAgC8MLtvaVOh8jqKOUyvDylDwDg68PpuHi5QuKMiIjaH4tXkoQoili5MxEAMHOAP/r4OEmcEZF1Gt/LEzf36ga9QcQrP5/l1FlE1OmxeCVJxJ6/jKMXi2GjkGHRxJ5Sp0Nk1ZbdGQ6VQoZDF4rw0+lsqdMhImpXLF6pwxmNIt7cmQQAmDMiCH4uaokzIrJuge52eGpC3cVbb/yaiNKqGokzIiJqPyxeqcP99+QlJOWVw9FWgQU395A6HaJO4Z9jQtDTywFFlTWmPw6JiDojFq/UoapqavHv3ckAgIU394CLnY3EGRF1DjYKGVbM6A8A2HQsC4cucOUtIuqcWLxSh/p8fxryNTr4u6oxZ2R3qdMh6lQGd3fDg1dW3nr+hzhoqjn3KxF1PixeqcMUaKrx6f5UAMCS23vDVimXOCOizufFyb0R5G6HnLJqLNt2Tup0iIjMjsUrdZh3d59HVY0BAwJdcEeEj9TpEHVKdjYKvHt3JAShbnz57oQ8qVMiIjIrFq/UIRJzNfj+RN366y9P6cNlYIna0eDubnhsbAgA4MUt8cjXVEucERGR+bB4pXYniiJW7EiEKAJT+vtgUJCb1CkRdXqLonqij48Tiipr8OTGU6g1GKVOiYjILFi8Urvbd/4yDqQUwkYuwxIuA0vUIVQKOT6ePRAOKgX+SivGqpjzUqdERGQWLF6pXdUajFixvW4Z2DkjgxDobidxRkRdR7CHPd78R930WR/vS8Xe5AKJMyIiajsWr9SuNh/PQkpBBVzslFh4c5jU6RB1OXdE+Jqmz3p64ylcvFwhcUZERG3D4pXajaZaj/eufFX59IQwONspJc6IqGt6+Y4+GBDoAk11LR5ddxxlVZz/lYisF4tXajcf/p6CwooahHazxwNXen6IqOOpFHJ89uBg+Drb4mJhJRZsOAk9L+AiIivF4pXaxYWCcnx9OB0A8OrUflDK+VYjklI3RxW+mDMEdjZyHLxQiFd/PgtRFKVOi4ioxVhRkNmJoojXf01ErVHErX08Ma5nN6lTIiIAfX2d8P69N0EmABv/ysK/dydLnRIRUYuxeCWz25N8GfvPX4aNXIaXp/SVOh0i+puJ/byxfEbdDAT/2ZuKLw5clDgjIqKWYfFKZlVrBFbsrOvNeWR0MLp72EucERFd7f6hgXjh9l4AgDe2J2LDn5kSZ0RE1HwsXsms9uUKyCzWwtNRhYW39JA6HSK6hv83LtS0hOxLW+PxzZF0aRMiImomhdQJUOdRUK7D7kt1fw8tub03HFQ3fntlZmaisLCwzcdOTExscwwia2KOz85tXiLyetpj2/lKvPpzAmpqjXh0TIiZMmwbc/1sAAAPDw8EBgaaJRYRSY/FK5nNv3efh84oINLfGTMG+N1w/8zMTPTu0wfaqiqz5VBRwQnYqfMz92fHY8I82A+egTe2J6JMq8eiqJ4QBMEssVvD3K9PbWeHpMREFrBEnQSLVzKLU5kl2Ho6FwDwypTekMlu/IuvsLAQ2qoqzF7yDrwCQ9t0/MS/YrFz3Qeorq5uUxwia2DOz05+ZirWv/U85s15EJsSKvDRngvILtXizZkRsFFIM7KsPV5fYWEhi1eiToLFK7WZwSji5Z/OAgCGdjMi0t+5Rc/3CgyFf1i/NuWQn5napucTWSNzfHbq3dPPEQN6B+OlrWex5WQ2CjQ6/GfWQElXxjPn6yOizoMXbFGbfXskHQk5GjjZKnBnEFftIbJW9w4JxBdzBpsWMrjzPweRnFcudVpERA2weKU2KdBU493d5wEAz0WFwVG6ThoiMoObe3nih8dHwN9VjYyiKsz4+BB+PZMjdVpERCaSFq/79+/H1KlT4evrC0EQ8NNPPzV4XBRFREdHw9fXF2q1GuPHj0dCQoI0yVKT/rU9EeW6WkQGuOC+wf5Sp0NEZtDP1xm/LByN0T08UFVjwMINp/DilnhoawxSp0ZEJG3xWllZicjISKxevbrJx99++22sWrUKq1evxrFjx+Dt7Y2oqCiUl/NrLEtwIOUyfonLgUwAlk8Pb9ZFWkRkHVztbfD1w0PwxPhQCAKw8a9MTF19EIm5/PlLRNKS9IKtSZMmYdKkSU0+Jooi3n//fSxduhQzZ84EAKxbtw5eXl7YsGED5s+f3+TzdDoddDqd6b5GowEA6PV66PV6M7+CrkunN+CVKxdpzR4WiF6edqbz29zzbDQaoVarIRcAQWxbj45CLoNarYZCJjBWR+Z05Q8WS3p95oxlzpzkAqBWq2E0Gtv8s8icn536vBITE2E0Nh6zfosH4DHaBR8d0+BCQQVmrDmCiX4Cup04CRuFvNH+Op0OKpWqTTklJyeb/fWZ47x3ZS39+U7SMPfPhvqYHdHuLTmGIIqi2I65NJsgCNi6dSumT58OALh48SJCQ0Nx8uRJDBgwwLTftGnT4OLignXr1jUZJzo6GsuWLWu0fcOGDbCzs2uX3LuiXVkCdl6Sw0kp4qWbDFBz3gqiTq1CD2xKlSG+pO4LOz87EfeHGhDgIHFiRNQpVFVVYdasWSgrK4OTk9N197XYkiMvLw8A4OXl1WC7l5cXMjIyrvm8F198EYsWLTLd12g0CAgIwMSJE294Mqh5Moqr8PyxwwCMWDY9AndE+ACo+6spJiYGUVFRUCpvfOVWXFwcxo4di4XvrodvaO825XQ6die+f+9l3P/Sh+g/dBRjdVBOZw/swtTBIdiRUIg+g0e2KVZnP1c5qUlY/dxs7N+/H5GRkW2K1R6fndseWYywfgOuu29vRyMc5DLElcqRXSXg3/FyhDgY0d/FAJUcSD5xEDEb1jQr1vXUx7G0896VtfTnO0nDnD8b8i8mYbiPDD4+Pg06EdtL/TflzWGxxWu9q1d5EUXxuiu/qFSqJr+yUiqV/MCZgSiK+Nf2ZNTUGjG6hwemDwxo1B7NPdcymQxarRYGERCFxl8/tkStwQitVotao8hYHZmTUTT9aymvz5yxzJmTQQS0Wi1kMlmbfxa1x2fHyTMAPj1uPKeqn2jA5LLz+O6SC5LzK3CxQo7saiVGhrrDwcOnRbGuJScj1SLPO/F3qaUz588Gg/i/mB3R5i05hsVOleXt7Q3gfz2w9QoKChr1xlLH2RaXg9jzl2Ejl+H1af0kXUKSiKThZANM6ueJuwb6w8PBBrpaI/YmX8ZpBEPl11fq9Iiok7PY4jU4OBje3t6IiYkxbaupqUFsbCxGjmzb15PUOkUVOiz75RwAYMHNPRDSjYPdiLoyP1c17h8SiPE9u0GlkKEStvB+4G2c1bmisEJ34wBERK0g6bCBiooKXLhwwXQ/LS0Np0+fhpubGwIDA/HMM89gxYoVCAsLQ1hYGFasWAE7OzvMmjVLwqy7rmW/nENxZQ16ezvi/41v23rjRNQ5yGQCIgNcEOblgG0HTiLP6IQiqLH+z0z09nbE8BB3OKv5NTMRmY+kxevx48dx8803m+7XX2g1Z84cfP3113jhhReg1WrxxBNPoKSkBMOGDcPu3bvh6OgoVcpd1u/n8rHtypyub98VARuFxXbaE5EE7GwUCEMeTn71IiLnv4dCgxpJeeU4n1+OcF9nDA12g73K4i+zICIrIOlPkvHjx+N6M3UJgoDo6GhER0d3XFLUSJlWj6U/xQMA/jk2BBH+LtImREQWq7boEvqpSuDTrycOpxYhs7gKZ7LLkJCrQbivEwYFucLRlj2xRNR6/DO4C8nMzERhYWGLn/fxsVLka3TwcZBjvHsVTp482eRE5PUTnMfFxUEmu3HPbGJiYotzISLr4OVkixkD/HCppAqHU4uQW1aNuEtliM8uQ18fJwzu7sbhBETUKixeu4jMzEz07tMH2qqqFj3PNigSXvctBwCc+nQxRr6ScOURAUDDXnO1Wo2NGzdi7Nix0Gq1zT5GRUVFi3IiIuvh72qHuwepkVWixbG0Ylwq1eJsjgYJuRr09nLEkO5ucLW3kTpNIrIiLF67iMLCQmirqjB7yTvwCmzexVa1RiAmV4kqAxDiYMA/XvwXACDxr1jsXPcBpsxfil4Rg0z71y8lt/Dd9ab54a6nPk51dXWLXw8RWQ9BEBDoZodANztkl9YVsRnFVUjMK0diXjl6ejpgSLAbPBzatqwsEXUNLF67GK/AUPiHNW/y8Njzl1FlKIWjrQK3DQo1XaSVn5kKAHD3DWoQSxANgPY8fEN7N2ty5Po4RNR1+Lmo4TfAD3maahxLK8bFwkqcL6jA+YIKhHjYY0iwm9QpEpGFY/FKTcoqrsLprFIAwC29PTm7ABGZlbeTLaZG+uJyuQ7H0ouRUlCBi4WVuFhYCRcEQOXf+hW6iKhzY/FKjej0Buw+lw8ACPd1Qnd3e4kzIqLOqpujCpP7+6C4sgbHM4qRlFeOUtEB3rPfwqlqHVyKKhHkZsfV/IjIhN1p1Mje85dRoauFs1qJMWHdpE6HiLoAN3sbTOzrjTkjusMbJRBr9dAYVfj5dA42HcvChYKK606tSERdB4tXauB8fjmS88ohCMBt/bw4XICIOpSzWokeyEP2p/Pgp6iAQiagoFyH7fG5WP9nJpLyNDAaWcQSdWWsTMikoroWe5IKAABDurvBx1ktcUZE1FUZKorRw0aDh0d1x5DurrCRy1BUWYPfEvLxzdEMnM0ug4FFLFGXxDGvBAAQRRG7E/OgqzXCy0mFod15xS8RSc/ORoGRoR4YFOiKuEtlOJVVgjKtHn8kFeDPtGIMCnJFuK8TFHL2xRB1FSxeCQAQd6kMWcVaKGQCbuvrDbmMF0cQkeVQKeUYGuyGAYEuiM8uw8mMElToahF7/jKOpxdjcHc3FrFEXQSLV0JRhQ4HL9QtGzs6zIOr3RCRxVLKZRgY6IoIP2ecy9XgeEYJyqvritgTGSUY3N0V/XydoGjGEtVEZJ1YvHZxeoMRO8/mwWAUEeRuhwg/Z6lTIiK6IYVchgh/F/Tzdca5HA3+Si9Gha4W+5Iv43h6CYYGu6Gvj5PUaRJRO2Dx2sXtS76Mosoa2NnIEdXHi3MpEpFVkcsE9Pd3Rh9fRyRka3Aso66I3ZNUgGPpxQizkwGyG6/4R0TWg9+rdGGJuRqcy9VAAHB7P2/Yq/i3DBFZJ4VMhsgAF8wd0R3jenaDnY0c5dW1OFmsgO+ja3AgU8sptog6CRavXVRRhc40LdawEDcEuNlJnBERUdsp5DLcFOCCuSO7Y0yYB1QyEUpXX7x3tBRTPjqIvckFXOyAyMqxeO2C9AYjdpzNQ61RRICbGkM4LRYRdTL1F3bd7qtHyf5vYKcUkJirwcNrj+Hez47iREaJ1CkSUSuxeO2C9iVfRvGVca639fWGjONciaiTUsgAzZHvsWayJx4bGwIbhQx/pRXjH2sO45/fHMf5/HKpUySiFmLx2sVkVMg4zpWIuhxHlQwvTe6DfYvH497BAZAJQMy5fNz2/n48930cLpVUSZ0iETUTi9cuRNmtO06V1F11y3GuRNQV+bqo8dZdEdj97DhMCveGKAL/PXkJt/w7Fq//cg5FFTqpUySiG2Dx2kVodEZ4znwZBlFAoJsdx7kSUZfWw9MBax4YhJ8WjMLIUHfUGIz46lAaxr69Fx/9kQJtjUHqFInoGli8dgG1BiPePVIChYs37BUiJoVznCsREQDcFOCC9Y8Ow7fzhiLczwmVNQa8G3Me4/+9Fz8cz4KB02sRWRwWr13A8h2JiC+ogbFGixEetbBVcsJuIqJ6giBgTFg3bFswGh/ePwB+Lmrka3R4/sczmPLhARxIuSx1ikT0NyxeO7nvj2dh7aF0AEDhr6vgbMNeBCKipshkAu6M9MUfz43DS5N7w8lWgaS8cjz45V946Ku/kJSnkTpFIgKL107tVGYJXt56FgBwbz8HaFOOSJwREZHls1XK8djYUMQ+fzMeGRUMpVzA/vOXMfmDA3jhxzjka6qlTpGoS2Px2knla6ox/9sTqDEYMbGvF+7u6yB1SkREVsXV3gavTu2L3xeNw5T+PjCKwPfHL2H8O/uwancyKnS1UqdI1CVxks9OqKqmFo99cxwF5Tr09HLAqntvwvmEM1KnRUQAEhMTLSIGNV+Quz3+M3sgHskowYodiTiRUYIP91zAhr+ysCiqJ+4Z7A+FvOV9QZmZmSgsLDRLjh4eHggMDDRLLCJLx+K1kzEYRTy18TTiLpXBxU6Jzx8aDAcuREAkOU1x3UU/DzzwgNliVlRUmC0W3digIFf8+PgI7Dqbh7d2JSG9qAovbY3H2kNpeHFyb9zcyxNCM2dyyczMRO8+faCtMs/iCGo7OyQlJrKApS6BVU0nIooiorcl4PfEfKgUMnw5ZzCC3O2lTouIAGgr6i72mTJ/KXpFDGpTrMS/YrFz3QeorubYy44mCAIm9ffBhD5eWP9nBj74IwUpBRV45OvjGBnqjpcm90G4n/MN4xQWFkJbVYXZS96BV2Bom3LKz0zF+reeR2FhIYtX6hJYvHYin+6/iG+PZkAQgA/uuwmDgrgQAZGlcfcNgn9YvzbFyM9MNVM21Fo2ChkeHhWMmQP98fG+C1h7KB2HU4swdfVBzBjgh8UTe8HXRX3DOF6BoW1+PxB1Nbxgq5P4+XQ23tyZBAB4ZUpf3B7uI3FGRESdn7NaiRcn9cEfi8Zh2k2+EEVgy8ls3PzvfXh7VxLKq/VSp0jU6bB47QSOpBZh8Q9xAIB5o4PxyOhgiTMiIupaAtzs8MF9A7Bt4SgMDXaDrtaIj/elYvw7+/DtkXToDUapUyTqNCy6eI2OjoYgCA1u3t7eUqdlUZLzyvHYt8ehN4iY3N8bSyf3kTolIqIuK8LfBZsfG47PHxqMkG72KKqswSs/J+C29/cj5lw+RJELxRC1lcWPee3Xrx9+//130325nEub1ksrrMQDX/6J8upaDA5yxap7boJM1rwrXYmIqH0IgoCovl4Y36sbNv2Vifd+T8HFy5X45zfHMTTYjZ0MRG1k8cWrQqFgb2sTLpVUYfbnR3G5XIfe3o74Ys5g2CpZ2BMRWQqlXIYHR3THtAF++GRfKr48mIa/0oox7T+HMCbQFnInT6lTJLJKFl+8pqSkwNfXFyqVCsOGDcOKFSsQEhJyzf11Oh10Op3pvkZTNz2NXq+HXt85Bs4XlOsw64u/kFNWjRAPO3w9ZyDslcJ1X5/RaIRarYZcAATR0KbjK+QyqNVqKGRCg1j1/29u/GvFMWdOjNXOOV3p6bek12fOWJaYk9Sxrvc5t8TzLhcAtVqNxMREGI1tH3eq0+mgUqla/LxbPICIiW7YmFCB2IxqHMisht8/P8HZUjm61dS0qfOh/jUajcZ2+z1XH7ez/B7trMz5u14u/C9mR7R7S44hiBY8AGfnzp2oqqpCz549kZ+fjzfeeANJSUlISEiAu7t7k8+Jjo7GsmXLGm3fsGED7Ozs2jvldlehBz5KkCNPK8BdJeKpfga4tPznKBERSSSrAvg5Q4YUTd1lJ/YKEbf5GzHKS4TCoq9EIWo/VVVVmDVrFsrKyuDk5HTdfS26eL1aZWUlQkND8cILL2DRokVN7tNUz2tAQAAKCwtveDIsnUarx4Nrj+Ncbjm8nFTY+OgQBLg2ryCPi4vD2LFjsfDd9fAN7d2mPE7H7sT3772M+1/6EP2HjjJtF0QDulenIt02FKJw416Ea8UxZ06M1b45nT2wC1MHh2BHQiH6DB7Zplid/Vx1lljX+5xb8nm/7ZHFCOs3oE2xkk8cRMyGNWaJlXTiIPYf/hN+0xej0qgEALioFRgd6o7QbnbNXqkLAHJSk7D6udnYv38/IiMj25TXtej1esTExCAqKgpKpbJdjkFtZ87f9fkXkzDcRwYfHx8MGNC293tzaDQaeHh4NKt4tfhhA39nb2+P/v37IyUl5Zr7qFSqJr/SUSqVVv2BK6/W49HvTuFcbjk8HGyw4Z/DEdLNodnPl8lk0Gq1MIhoVmF5PbUGI7RaLWqNYpOxREHerGPcKI45c2KsdsrJKJr+tZTXZ85YlpiTpcRq6nNuyefdyTMAPj3athhATkaqWWOVJR7CnffOgSLoJhy9WIRSbS1+PZsPH2dbjA3rBm9n22bFMoiAVquFTCZr999z1v67tLMz5+96g/i/mB3R5i05hlV9QaHT6ZCYmAgfn641AX9pVQ1mf/EnTmWWwlmtxLfzhiG0BYUrERFZJkEA+vs5Y86I7hja3Q0KmYDcsmpsPp6FX8/koKhCd+MgRF2MRfe8Ll68GFOnTkVgYCAKCgrwxhtvQKPRYM6cOVKn1mEul+vw4Jd/IimvHG72NvjmkaHo42Pdwx+IiKghG4UMI0Ld0d/PGUcuFuFcrgaplyuRerkSvb0dMTzEHc5q9ngSARZevF66dAn3338/CgsL0a1bNwwfPhxHjx5FUFCQ1Kl1iNwyLWZ/8ScuXq5EN0cVNjw6DGFejlKnRURE7cTBVoGovl4YGOiCIxeLkHq5Ekl55TifX45+vs4YGuwGB5VF/+omancW/QnYtGmT1ClIJqu4CrO+OIqsYi18nW2x/p/DEexhL3VaRETUAdwdVLgjwhd5mmocSS1CZnEV4rPLcC5Xg5v8XTCouyvUnNubuiiLLl67qouXKzD7iz+RW1aNIHc7rH90GPybOasAERF1Ht5OtpgxwA+XSqpwOLUIuWXVOJFZgvjsMgwIdMFNAS5Sp0jU4Vi8WpiTmSV4dN1xFFfWoIenA9Y/OgxeTs274pSIiDonf1c73D1IjfSiKhxOLURhRQ3+TCvGqcxSBNvLIVPzWgjqOli8WpBdZ/Pw9KZT0NUaEe7nhHUPD4W7A1cgICIiQBAEBHvYo7u7HS4UVODP9GIUVdQgWSOH3+Nf4ps4DQLCdOjmyN8b1LmxeLUQaw+l4fVfz0EUgVt6e+Kj+wfAnoPyiYjoKoIgIMzLET08HZB6uRKHkrJRCjV+Sq7Errf34J7BAZg3OhhB7rxOoqsyinULG1XoalGpq4Wu1ghdrRE1BiNEUYRRBAQACrkApVwGG4UM9jYK2NnI4WirsPjx1KyOJGY0ili+IxFfHkwDAMwaFojX7+wHhdyqpuAlIqIOJggCeng6QFVai09WrcCo+cuRUqzHN0cy8O3RDNzezxuPjgnBoCBXqVOldlKtNyA5rxwXCipw4XIFjp8vhu8/P8VPWUqIWemtjqtSyGAvUyC9Cnje1/IWYmXxKqFqvQHPbj6NnWfzAABLbu+Nx8eFtGhZQCIi6toEAdBePI43J7hD5xyEzw5cxL7ky9h5Ng87z+ZhUJAr/jkmGLf28WLHiBUTRREZRVU4lVWCU5mlOJVZisRcjWmlw3pKNz+IAOQyAfY2ctirFLBVyqFSyGAjl0EmCBAEQETdCnR6owid3oCqGgMqdbWorDHU9dRChgsa0SJrEhavErlUUoXHvzuBs9ka2MhleOfuCEy7yU/qtIiIyEoJgoCRPTwwsocHzueX44sDF/HTqRycyCjBiYwS+Djb4r4hgbhvaAAvBLYCoigirbASh1KLcPhCIf5MK0ZxZU2j/dztbRDm5YAeng6w1ZVi+ZIn8fCi19Cjd99WFZ61BiNKtXpcTE1FmKtl/rHD4lUChy4UYuGGkyip0sPVTok1DwzC8BB3qdMiIqJOoqeXI96+KxKLJ/bCuiPp2PhXFnLLqvHe7+fx4Z4UTOzrhQeGB2FkqLtF9qx1VXll1Th0oRCHUgtx5MrUaH9nI5ch3M8JAwJdMSDQBQMCXeHrbGtqw5MnT+KVjDioFWh1uyrkMng4qKC3FzHIw/KGDAAsXjuUKIr4bP9FvLUrCUaxbj3rNQ8M5ByuRETULjydbPH8bb3x1IQw7IzPw3dHM3A8o8Q0pCDQzQ7TB/hh+k2+COnmIHW6XU5pVQ2OXizCoQtFOJRaiIuXKxs8biOXYWCQC0aFemBkD3eE+zlDpbDsi6k6AovXDlKpq8UL/z2D7WdyAQB3DfLHG9PDYWvhV/QREZH1UynkdUXqAD8k5Wmw/mgmtp7KRmZxFT78IwUf/pGCyAAXTL/JF1MjfeHBaRrbRVVNLY6nl+BQaiEOXyjC2ZwyiH/r3BSEuo6tkaEeGNXDHYOD3KC2YZ1wNRav7SAzMxOFhYX/u1+mx7tHSpGlqYVcAB4Z4ITbQ2pxLj7uhrF0Oh1Uqrb/EElMTGxzDCIisn69vZ3wr+nheHFyb8Scy8fWU9k4kFKIuKxSxGWV4o3tiRjS3RVRfb0R1ccLge6t+3bw6t+FbeHh4YHAwECzxDJXXs3JSVOtx/H0YvyZVow/LxbjbHZZowuseng6YFSoO0b28MDwYHc42ynbnFtnx+LVzDIzM9G7Tx9oq6oAAI4D74DL+IchU6pQW1GMvJ/exMtvnsPLzY4ooO6aQPOoqKgwWywiIrJedjYKTLvJD9Nu8sPlch1+PZODn05lI+5SGY5eLMbRi8X416/n0NPLAbf06gbbckBvMELZjNrq6t+FbaW2s0NSYmKbC1hz5tVUTkUVOhxLL8FfacX4M60IibkaXFWrws9FjRGh7hjVwx0jQz148VwrsHg1s8LCQmirqnD3klXItO2BvOq6K/W8bI0Y7OcA25feaHasxL9isXPdB5gyfyl6RQxqU171saqrq2+8MxERdSndHFV4eFQwHh4VjIyiSvyeWIDfz+Xjr/RinM+vwPn8CgAKfHZ+LwZ3d8PwEDcMD3FHfz9nKJuYfqv+d+HsJe/AKzC0TbnlZ6Zi/VvPo7CwsM3Fq7nyys9MxYb3XsW+c9nQpulx5lIZ4i6V4lKJttG+3d3tMDTYDcOC3TE02A0BbrzOpa1YvLYD2+CBiJOFQVctQC4TMLqHByL9nVt85V9+ZioAwN03CP5h/dqUU30sIiKi6wlyt8e80cGYNzoYZVV67DtfgN/O5mJfUh6qagzYf/4y9p+/DACws5Ej0t8F4X5OCPdzRj9fJwR7/O/CL6/A0Db//moPLcnLaBRRqtWjqEKHwsoaFFXokK/ojYBnNuPVfcUAihvs38PTAcOC3TAsxB1Du7vB25k9q+bG4tWMqvUGfHmqDF73vA6dsW7utdvDvTnwnYiIrJKznRLTbvLD5H6e+HV7NnoMGoPjmWU4erEIf6YVo7RKjyMXi3DkYpHpOWqlHIFOMrhPegpJZTJo88vhYmcDFztlk720UhNFEbpaIyp0tdBo9Si7civV6qHR6qHR1sIgXj18T4AgCPCwk2FwsCciApyvFPHOcFZzzGp7Y/FqZnH5dRMIhzoYcPvgAK5mQkREnYJMAHp7O6J/gBseHhUMo1HE+YJynLlUhoTsMpzN0eBcjgZavQHJRQY4RExEQhmQUJZnimF3ZcUne9O/Ctip5FAr5bC5sgKUSiGr+79CBrkgoFHdeA16gxFVNQZU6w3Q1tStGKXV19YVolV1t6SL5XC9dT7+LJTjSFkWKmsMqNDVwnD1wNSrKOUC3Oxt4OGggru9DYxludj4ysPYcuAPDBw4sC2nlVqBxasZ2SrleHa4Cx7850L847mXWLgSEVGnJZMJ6O3thN7eTsDgAACAwSgirbAC2w+fwWvvrEbEbfejRmGP0qoaVNfWFZdVNQZcbtGRbBD4/M+498dc2Py0CzKZAKNRhFEEDKIIo1GEQRSbXeQ6DZqKS1UA0PAaEFuFDI5qJZyv3FzUSjhd+dfRVtFg6N+llBwYq0pb9CrIfFi8mlmwixLai8elToOIiKjDyWUCeng6YkygGmWHN2HI7HvgH1ZX2FbrDdBo9aisMaBSV4vKmlpU6gyoqqlFtd6IGoMRNbVG6GoNqKk1NrhKX5DJoTcC+hpDs3KwU8pha1PXo+tid6UYtbOBvqIUm779CmMn3wV/f/+63t8rPcHscLIeLF6JiIio3dkq5c1emEcURRiu9KheupCET16chw8+Wo3g0B4winVDGGQCIEAw/d9GLsBGLkAhu9bSqCISE3Pw6YHvEHbfTPh7OZr3BVKHYfFKREREFkUQBCjkAhQAdGWXYagswcJHZpstPuc8t24sXomIiMhiaSs0AMA5z8mExSsRERFZPM55TvU4OpmIiIiIrAaLVyIiIiKyGixeiYiIiMhqsHglIiIiIqvB4pWIiIiIrAZnGyAiIuoEEhMT2xxDp9NBpVI12m40GgEAcXFxkMlu3O9ljlysgble57XOe0t1lfPO4pWIiMiKaYovAwAeeOABM0QTAIiNtqrVamzcuBFjx46FVqttdrTOuhiAec85cK3z3lqd9bzXY/FKRERkxcw1iX/9BP5NxZFfWW114bvrYWhGjdXZFwNoj4UTuAhD87F4JSIi6gTaOol//QT+TcURRAOgPQ/f0N4QBXmzY3V25lw4gYswNB8v2CIiIiIiq8HilYiIiIishlUUrx9//DGCg4Nha2uLQYMG4cCBA1KnREREREQSsPjidfPmzXjmmWewdOlSnDp1CmPGjMGkSZOQmZkpdWpERERE1MEsvnhdtWoV5s2bh0cffRR9+vTB+++/j4CAAKxZs0bq1IiIiIiog1n0bAM1NTU4ceIE/u///q/B9okTJ+Lw4cNNPken00Gn05nul5WVAQCKi4uh1+vbL9krNBoNbG1tkXsxEbXVVW2KVZyTDltbWxRduoD0eDuLjyUXAC9vGTIvnmzWVCrW9vo6Syxz5lSSm4GqKh8UX0pFup26TbE6+7nqLLGu9znnebfuWNeLw5/vlp+TuWOV5GWiyqU7NBoNioqK2hSrOcrLywEAotiMN5howbKzs0UA4qFDhxpsX758udizZ88mn/Paa6+JqJvplzfeeOONN9544403K7plZWXdsD606J7XeoIgNLgvimKjbfVefPFFLFq0yHTfaDSiuLgY7u7u13wOmYdGo0FAQACysrLg5OQkdTrUAdjmXQ/bvGtiu3c9Hd3moiiivLwcvr6+N9zXootXDw8PyOVy5OXlNdheUFAALy+vJp+jUqkarQ/s4uLSXilSE5ycnPjDrYthm3c9bPOuie3e9XRkmzs7OzdrP4u+YMvGxgaDBg1CTExMg+0xMTEYOXKkRFkRERERkVQsuucVABYtWoQHH3wQgwcPxogRI/DZZ58hMzMTjz/+uNSpEREREVEHs/ji9d5770VRURFef/115ObmIjw8HDt27EBQUJDUqdFVVCoVXnvttUbDNqjzYpt3PWzzront3vVYcpsLoticOQmIiIiIiKRn0WNeiYiIiIj+jsUrEREREVkNFq9EREREZDVYvBIRERGR1WDxSi22f/9+TJ06Fb6+vhAEAT/99FODx0VRRHR0NHx9faFWqzF+/HgkJCRIkyy12cqVKzFkyBA4OjrC09MT06dPR3JycoN92Oadz5o1axAREWGaoHzEiBHYuXOn6XG2eee2cuVKCIKAZ555xrSNbd75REdHQxCEBjdvb2/T45ba5ixeqcUqKysRGRmJ1atXN/n422+/jVWrVmH16tU4duwYvL29ERUVhfLy8g7OlMwhNjYWCxYswNGjRxETE4Pa2lpMnDgRlZWVpn3Y5p2Pv78/3nzzTRw/fhzHjx/HLbfcgmnTppl+cbHNO69jx47hs88+Q0RERIPtbPPOqV+/fsjNzTXd4uPjTY9ZbJuLRG0AQNy6davpvtFoFL29vcU333zTtK26ulp0dnYWP/nkEwkyJHMrKCgQAYixsbGiKLLNuxJXV1fxiy++YJt3YuXl5WJYWJgYExMjjhs3Tnz66adFUeTnvLN67bXXxMjIyCYfs+Q2Z88rmVVaWhry8vIwceJE0zaVSoVx48bh8OHDEmZG5lJWVgYAcHNzA8A27woMBgM2bdqEyspKjBgxgm3eiS1YsABTpkzBrbfe2mA727zzSklJga+vL4KDg3Hffffh4sWLACy7zS1+hS2yLnl5eQAALy+vBtu9vLyQkZEhRUpkRqIoYtGiRRg9ejTCw8MBsM07s/j4eIwYMQLV1dVwcHDA1q1b0bdvX9MvLrZ557Jp0yacPHkSx44da/QYP+ed07Bhw/DNN9+gZ8+eyM/PxxtvvIGRI0ciISHBotucxSu1C0EQGtwXRbHRNrI+CxcuxJkzZ3Dw4MFGj7HNO59evXrh9OnTKC0txX//+1/MmTMHsbGxpsfZ5p1HVlYWnn76aezevRu2trbX3I9t3rlMmjTJ9P/+/ftjxIgRCA0Nxbp16zB8+HAAltnmHDZAZlV/lWL9X2z1CgoKGv31RtblySefxLZt27B37174+/ubtrPNOy8bGxv06NEDgwcPxsqVKxEZGYkPPviAbd4JnThxAgUFBRg0aBAUCgUUCgViY2Px4YcfQqFQmNqVbd652dvbo3///khJSbHozzmLVzKr4OBgeHt7IyYmxrStpqYGsbGxGDlypISZUWuJooiFCxdiy5Yt2LNnD4KDgxs8zjbvOkRRhE6nY5t3QhMmTEB8fDxOnz5tug0ePBizZ8/G6dOnERISwjbvAnQ6HRITE+Hj42PRn3MOG6AWq6iowIULF0z309LScPr0abi5uSEwMBDPPPMMVqxYgbCwMISFhWHFihWws7PDrFmzJMyaWmvBggXYsGEDfv75Zzg6Opr+Cnd2doZarTbNBck271xeeuklTJo0CQEBASgvL8emTZuwb98+7Nq1i23eCTk6OprGsdezt7eHu7u7aTvbvPNZvHgxpk6disDAQBQUFOCNN96ARqPBnDlzLPtzLt1EB2St9u7dKwJodJszZ44oinXTa7z22muit7e3qFKpxLFjx4rx8fHSJk2t1lRbAxDXrl1r2odt3vk88sgjYlBQkGhjYyN269ZNnDBhgrh7927T42zzzu/vU2WJItu8M7r33ntFHx8fUalUir6+vuLMmTPFhIQE0+OW2uaCKIqiRHUzEREREVGLcMwrEREREVkNFq9EREREZDVYvBIRERGR1WDxSkRERERWg8UrEREREVkNFq9EREREZDVYvBIRERGR1WDxSkRERERWg8UrERGZpKenQxAEnD59WupUiIiaxOKViOgKQRCue5s7d65kuXXv3h3vv/++ZMcnIrIUCqkTICKyFLm5uab/b968Ga+++iqSk5NN29RqdYvi1dTUwMbGxmz5ERERe16JiEy8vb1NN2dnZwiCYLqvVCrx+OOPw9/fH3Z2dujfvz82btzY4Pnjx4/HwoULsWjRInh4eCAqKgoAsG3bNoSFhUGtVuPmm2/GunXrIAgCSktLTc89fPgwxo4dC7VajYCAADz11FOorKw0xc3IyMCzzz5r6gVuyv3334/77ruvwTa9Xg8PDw+sXbsWALBr1y6MHj0aLi4ucHd3xx133IHU1NRrnpOvv/4aLi4uDbb99NNPjXL45ZdfMGjQINja2iIkJATLli1DbW3ttU82EVErsXglImqG6upqDBo0CL/++ivOnj2Lxx57DA8++CD+/PPPBvutW7cOCoUChw4dwqeffor09HTcddddmD59Ok6fPo358+dj6dKlDZ4THx+P2267DTNnzsSZM2ewefNmHDx4EAsXLgQAbNmyBf7+/nj99deRm5vboIf472bPno1t27ahoqLCtO23335DZWUl/vGPfwAAKisrsWjRIhw7dgx//PEHZDIZZsyYAaPR2Opz89tvv+GBBx7AU089hXPnzuHTTz/F119/jeXLl7c6JhHRNYlERNTI2rVrRWdn5+vuM3nyZPG5554z3R83bpx40003NdhnyZIlYnh4eINtS5cuFQGIJSUloiiK4oMPPig+9thjDfY5cOCAKJPJRK1WK4qiKAYFBYnvvffedfOpqakRPTw8xG+++ca07f777xfvvvvuaz6noKBABCDGx8eLoiiKaWlpIgDx1KlToig2fR62bt0q/v3Xx5gxY8QVK1Y02Ofbb78VfXx8rpsvEVFrsOeViKgZDAYDli9fjoiICLi7u8PBwQG7d+9GZmZmg/0GDx7c4H5ycjKGDBnSYNvQoUMb3D9x4gS+/vprODg4mG633XYbjEYj0tLSmp2jUqnE3XffjfXr1wOo62X9+eefMXv2bNM+qampmDVrFkJCQuDk5ITg4GAAaPQ6WuLEiRN4/fXXG+T/z3/+E7m5uaiqqmp1XCKipvCCLSKiZnj33Xfx3nvv4f3330f//v1hb2+PZ555BjU1NQ32s7e3b3BfFMVG40NFUWxw32g0Yv78+XjqqacaHTcwMLBFec6ePRvjxo1DQUEBYmJiYGtri0mTJpkenzp1KgICAvD555/D19cXRqMR4eHhjV5HPZlM1ihfvV7fKP9ly5Zh5syZjZ5va2vbovyJiG6ExSsRUTMcOHAA06ZNwwMPPACgrmBLSUlBnz59rvu83r17Y8eOHQ22HT9+vMH9gQMHIiEhAT169LhmHBsbGxgMhhvmOXLkSAQEBGDz5s3YuXMn7r77btOMB0VFRUhMTMSnn36KMWPGAAAOHjx43XjdunVDeXk5KisrTYX51XPADhw4EMnJydfNn4jIXDhsgIioGXr06IGYmBgcPnwYiYmJmD9/PvLy8m74vPnz5yMpKQlLlizB+fPn8f333+Prr78GAFOP7JIlS3DkyBEsWLAAp0+fRkpKCrZt24Ynn3zSFKd79+7Yv38/srOzUVhYeM3jCYKAWbNm4ZNPPkFMTIyp2AYAV1dXuLu747PPPsOFCxewZ88eLFq06Lr5Dxs2DHZ2dnjppZdw4cIFbNiwwZR/vVdffRXffPMNoqOjkZCQgMTERGzevBkvv/zyDc8PEVFLsXglImqGV155BQMHDsRtt92G8ePHw9vbG9OnT7/h84KDg/Hjjz9iy5YtiIiIwJo1a0yzDahUKgBAREQEYmNjkZKSgjFjxmDAgAF45ZVX4OPjY4rz+uuvIz09HaGhoejWrdt1jzl79mycO3cOfn5+GDVqlGm7TCbDpk2bcOLECYSHh+PZZ5/FO++8c91Ybm5u+O6777Bjxw7T9GDR0dEN9rntttvw66+/IiYmBkOGDMHw4cOxatUqBAUF3fD8EBG1lCBePZiJiIja1fLly/HJJ58gKytL6lSIiKwOx7wSEbWzjz/+GEOGDIG7uzsOHTqEd955xzSHKxERtQyLVyKidpaSkoI33ngDxcXFCAwMxHPPPYcXX3xR6rSIiKwShw0QERERkdXgBVtEREREZDVYvBIRERGR1WDxSkRERERWg8UrEREREVkNFq9EREREZDVYvBIRERGR1WDxSkRERERWg8UrEREREVmN/w+alzJ943NgFQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the distribution of target train values with a histogram from matplotlib.pyplot (imported as plt):\n",
    "# import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the distribution of the target variable\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(y_train, kde=True, bins=30)\n",
    "plt.title(\"Distribution of Target Variable (y_train)\")\n",
    "plt.xlabel(\"Target value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are completely done with the data preprocessing, we move on to training MLPRegressor() from sklearn.neural_network: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html. After examining the possible hyperparameters, which can be specified in MLPRegressor(), we will train two neural models. The latter should use the Adam optimizer with the learning rate=0.001. Additionally, the first neural network should have a single Tanh-based hidden layer with 10 units, while the second network should apply ReLU in two hidden layers with the number of units [10,5]. Once the training process is complete, we will compare the performance of the two models on the test set using MSE. We defined the latter in a function in the first part of the notebook (the demo showing the forward passes). If you re-run the models several times, do you observe differences in the results? If yes, then why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Tanh, 1 layer [10], Test MSE: 448.8436\n",
      "Model ReLU, 2 layers [10,5], Test MSE: 34.7204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#Your implementation of the MLPRegressors: \n",
    "\n",
    "# define the models\n",
    "tanh_MLP = MLPRegressor(hidden_layer_sizes=(10, ), activation=\"tanh\", solver=\"adam\", learning_rate_init=0.001)\n",
    "relu_MLP= MLPRegressor(hidden_layer_sizes=(10, 5), activation=\"relu\", solver=\"adam\", learning_rate_init=0.001)\n",
    "\n",
    "# fit the models (train)\n",
    "tanh_MLP.fit(x_train_scaled, y_train)\n",
    "relu_MLP.fit(x_train_scaled, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred_tanh = tanh_MLP.predict(x_test_scaled)\n",
    "y_pred_relu = relu_MLP.predict(x_test_scaled)\n",
    "\n",
    "# compare / evaluate using mse\n",
    "tanh_mse = mse(true_target=y_test, predictions=y_pred_tanh)\n",
    "relu_mse = mse(true_target=y_test, predictions=y_pred_relu)\n",
    "\n",
    "# print results\n",
    "print(f\"Model Tanh, 1 layer [10], Test MSE: {round(tanh_mse, 4)}\")\n",
    "print(f\"Model ReLU, 2 layers [10,5], Test MSE: {round(relu_mse, 4)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If you re-run the models several times, do you observe differences in the results? If yes, then why?\n",
    "\n",
    " -> we did not set the random_state parameter.\n",
    " - the MLPRegressor randomly intitialize weights of the network\n",
    " - it may shuffle the training data internally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Hyperparameter Tuning using Optuna.** <br>(Excercise 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna represents an automatic hyperparameter optimization software framework, which supports multiple samplers, including the Tree-Parzen Estimator (TPE). This name implies a tree-structured search space, i.e., a search space that includes some conditional parameters, and use Parzen estimators such as kernel density estimators (KDEs). In a nutshell, TPE models the probability distribution of good and bad hyperparameter configurations, and then uses that to guide the search, i.e., to achieve a balance between exploration (trying new areas) and exploitation (focusing on promising regions).<br>\n",
    "\n",
    "Before we move on with the encoding of the search space using optuna, take a look at some code examples under the link: https://optuna.org/#code_examples. The hyperparameter tuning with optuna consists mainly of 5 aspects:\n",
    "- the definition of an objective function, which encodes the potentially conditional search space.\n",
    "- the creation of a study with optuna using a specific sampler, e.g., TPE. The study object should also  <br> \n",
    "  receive the direction for the optimization of the chosen metric, i.e., maximize accuracy or minimize an error metric.\n",
    "- the optimization of the hyperparameters for a pre-defined number of trials based on a score computed on the validation set. \n",
    "- extraction of the best hyperparameter configuration, and application of the best performing model on the test set.\n",
    "\n",
    "Next, we will reserve the last 104 samples from our train dataset for validation purposes, and we will define the following search space in Optuna's objective function:\n",
    "- for a maximum of 3 hidden layers sample values in [10,200] with stepsize=10. For deeper hidden layers allow optuna to sample also 0 units, indicating the network is not grown deeper.\n",
    "- Optimizer: ['adam','sgd']\n",
    "- Learning_Rate: [0.0001,0.001] with stepsize=0.0001\n",
    "- Activation=['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "Additionally, the alpha parameter, i.e., the L2 regularization coefficient, is set to the rather high value of 0.01 during the tuning process to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "#We reserve 104 samples from our training dataset for validation purposes. We should rescale the new\n",
    "#train and validation subsets: \n",
    "x_train_optuna, x_val_optuna = x_train[:-104], x_train[-104:]\n",
    "y_train_optuna, y_val_optuna = y_train[:-104], y_train[-104:]\n",
    "\n",
    "#We rescale the new train and validation subsets:\n",
    "\n",
    "# define a scaler using StandardScaler\n",
    "scaler_optuna = StandardScaler()\n",
    "scaler_optuna.fit(x_train_optuna)\n",
    "\n",
    "\n",
    "x_train_optuna_rescaled = scaler_optuna.transform(x_train_optuna)\n",
    "x_val_optuna_rescaled = scaler_optuna.transform(x_val_optuna)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main structure of the objective function is already defined. Therefore, you would have to fill in the missing code in order to create the search space. If the code runs error free, you should be able to execute the optimization (two cells below the current cell, where we call study.optimize). The comments in the objective function highlight the functionality that has to be implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the objective as python function: \n",
    "\n",
    "def objective(trial: optuna.Trial) -> np.float64:\n",
    "    '''\n",
    "    Perform hyperparameter tuning using optuna.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    trial:optuna.Trial\n",
    "        An optuna run with a specific hyperparameter configuration sampled in this function.\n",
    "\n",
    "    Returns: \n",
    "    ---------\n",
    "    mse_val: np.float64\n",
    "        The mse error score achieved on the validation set.\n",
    "    '''\n",
    "\n",
    "    #Sample number of neurons for a pre-defined maximum number of hidden layers: \n",
    "    # here you need to consider conditional hyperparameters:\n",
    "    max_hidden_layers=3\n",
    "    hidden_units_list=[]\n",
    "    keep_sampling_hidden_units=True\n",
    "    nr_hidden_layer=0\n",
    "\n",
    "    #Keep on sampling the number of hidden units until you have reached the max number of layers\n",
    "    #or until optuna has sampled 0 units indicating the network should not be grown deeper:\n",
    "    while keep_sampling_hidden_units:\n",
    "        if nr_hidden_layer==0:\n",
    "            current_hidden_units=trial.suggest_int(\"Units_hidden_layer_\"+str(nr_hidden_layer), low=10, high=200, step=10)\n",
    "        else:\n",
    "            current_hidden_units = trial.suggest_int(\"Units_hidden_layer_\"+str(nr_hidden_layer), low=0, high=200, step=10)\n",
    "        \n",
    "        #Terminate the training if max number of layers reached or currently sampled units are 0:\n",
    "        if nr_hidden_layer >= max_hidden_layers or current_hidden_units == 0:\n",
    "            keep_sampling_hidden_units = False\n",
    "        \n",
    "        #Save the sampled number of units in the list hidden_units_list unless optuna has sampled 0 units:\n",
    "        else:\n",
    "            hidden_units_list.append(current_hidden_units)\n",
    "            nr_hidden_layer=nr_hidden_layer+1\n",
    "\n",
    "    # if no layers were added (e.g., 0 was drawn at first layer), fall back to one default layer\n",
    "    if len(hidden_units_list) == 0:\n",
    "        hidden_units_list = [10]\n",
    "    \n",
    "    #Non-conditional hyperparameters:\n",
    "    current_optimizer = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    current_learning_rate =  trial.suggest_float(\"learning_rate\", 0.0001, 0.001, step=0.0001)\n",
    "    current_activation = trial.suggest_categorical(\"activation\", [\"identity\", \"logistic\", \"tanh\", \"relu\"])\n",
    "    \n",
    "    #Implementation of an MLPRegressor using the hyperparameters sampled in the current trial.\n",
    "    #Don't forget to also set the L2 parameter to a rather high value, e.g., 0.01, to avoid overfitting:\n",
    "    current_MLP_regressor= MLPRegressor(hidden_layer_sizes=tuple(hidden_units_list),\n",
    "                                         activation=current_activation,\n",
    "                                         solver=current_optimizer,\n",
    "                                         learning_rate_init=current_learning_rate,\n",
    "                                         alpha=0.01,  # L2 regularization\n",
    "                                         max_iter=500)  # reasonable default\n",
    "    \n",
    "    #Fit on the training set and evaluate the performance on validation set:\n",
    "    current_MLP_regressor.fit(x_train_optuna_rescaled,y_train_optuna)\n",
    "    val_predictions=current_MLP_regressor.predict(x_val_optuna_rescaled)\n",
    "\n",
    "    mse_val = mse(y_val_optuna, val_predictions)\n",
    "    return mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 12:51:32,797] A new study created in memory with name: no-name-74b35ae3-2602-4beb-90eb-be1ff89b7b65\n",
      "[I 2025-05-26 12:51:33,616] Trial 0 finished with value: 29.163394110212444 and parameters: {'Units_hidden_layer_0': 140, 'Units_hidden_layer_1': 200, 'Units_hidden_layer_2': 110, 'Units_hidden_layer_3': 20, 'optimizer': 'sgd', 'learning_rate': 0.0001, 'activation': 'identity'}. Best is trial 0 with value: 29.163394110212444.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:51:36,722] Trial 1 finished with value: 81.0160129105887 and parameters: {'Units_hidden_layer_0': 170, 'Units_hidden_layer_1': 80, 'Units_hidden_layer_2': 70, 'Units_hidden_layer_3': 130, 'optimizer': 'adam', 'learning_rate': 0.001, 'activation': 'logistic'}. Best is trial 0 with value: 29.163394110212444.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:51:37,118] Trial 2 finished with value: 170.6721379339752 and parameters: {'Units_hidden_layer_0': 20, 'Units_hidden_layer_1': 50, 'Units_hidden_layer_2': 0, 'optimizer': 'adam', 'learning_rate': 0.0001, 'activation': 'identity'}. Best is trial 0 with value: 29.163394110212444.\n",
      "[I 2025-05-26 12:51:37,310] Trial 3 finished with value: 30.11983656667561 and parameters: {'Units_hidden_layer_0': 100, 'Units_hidden_layer_1': 190, 'Units_hidden_layer_2': 10, 'Units_hidden_layer_3': 110, 'optimizer': 'sgd', 'learning_rate': 0.0006000000000000001, 'activation': 'identity'}. Best is trial 0 with value: 29.163394110212444.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:51:42,323] Trial 4 finished with value: 11.667238684570426 and parameters: {'Units_hidden_layer_0': 190, 'Units_hidden_layer_1': 140, 'Units_hidden_layer_2': 180, 'Units_hidden_layer_3': 40, 'optimizer': 'adam', 'learning_rate': 0.0009000000000000001, 'activation': 'relu'}. Best is trial 4 with value: 11.667238684570426.\n",
      "[I 2025-05-26 12:51:42,456] Trial 5 finished with value: 101.89597295096942 and parameters: {'Units_hidden_layer_0': 10, 'Units_hidden_layer_1': 130, 'Units_hidden_layer_2': 110, 'Units_hidden_layer_3': 10, 'optimizer': 'sgd', 'learning_rate': 0.0008, 'activation': 'logistic'}. Best is trial 4 with value: 11.667238684570426.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:51:46,658] Trial 6 finished with value: 8.040833473420086 and parameters: {'Units_hidden_layer_0': 120, 'Units_hidden_layer_1': 70, 'Units_hidden_layer_2': 140, 'Units_hidden_layer_3': 20, 'optimizer': 'sgd', 'learning_rate': 0.0006000000000000001, 'activation': 'tanh'}. Best is trial 6 with value: 8.040833473420086.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:51:49,970] Trial 7 finished with value: 33.03149402923688 and parameters: {'Units_hidden_layer_0': 190, 'Units_hidden_layer_1': 90, 'Units_hidden_layer_2': 130, 'Units_hidden_layer_3': 100, 'optimizer': 'adam', 'learning_rate': 0.00030000000000000003, 'activation': 'tanh'}. Best is trial 6 with value: 8.040833473420086.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:51:50,433] Trial 8 finished with value: 22.418357128537203 and parameters: {'Units_hidden_layer_0': 50, 'Units_hidden_layer_1': 0, 'optimizer': 'sgd', 'learning_rate': 0.001, 'activation': 'logistic'}. Best is trial 6 with value: 8.040833473420086.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:51:54,822] Trial 9 finished with value: 15.545515652121212 and parameters: {'Units_hidden_layer_0': 140, 'Units_hidden_layer_1': 160, 'Units_hidden_layer_2': 150, 'Units_hidden_layer_3': 120, 'optimizer': 'adam', 'learning_rate': 0.0009000000000000001, 'activation': 'tanh'}. Best is trial 6 with value: 8.040833473420086.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:51:56,938] Trial 10 finished with value: 9.798523040353917 and parameters: {'Units_hidden_layer_0': 80, 'Units_hidden_layer_1': 30, 'Units_hidden_layer_2': 200, 'Units_hidden_layer_3': 200, 'optimizer': 'sgd', 'learning_rate': 0.0005, 'activation': 'tanh'}. Best is trial 6 with value: 8.040833473420086.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:51:59,509] Trial 11 finished with value: 8.846465951311881 and parameters: {'Units_hidden_layer_0': 80, 'Units_hidden_layer_1': 20, 'Units_hidden_layer_2': 200, 'Units_hidden_layer_3': 200, 'optimizer': 'sgd', 'learning_rate': 0.0005, 'activation': 'tanh'}. Best is trial 6 with value: 8.040833473420086.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:02,919] Trial 12 finished with value: 8.036427908312207 and parameters: {'Units_hidden_layer_0': 70, 'Units_hidden_layer_1': 50, 'Units_hidden_layer_2': 170, 'Units_hidden_layer_3': 200, 'optimizer': 'sgd', 'learning_rate': 0.0006000000000000001, 'activation': 'tanh'}. Best is trial 12 with value: 8.036427908312207.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:06,420] Trial 13 finished with value: 8.911486652325998 and parameters: {'Units_hidden_layer_0': 130, 'Units_hidden_layer_1': 60, 'Units_hidden_layer_2': 160, 'Units_hidden_layer_3': 70, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'tanh'}. Best is trial 12 with value: 8.036427908312207.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:08,885] Trial 14 finished with value: 11.476744127737906 and parameters: {'Units_hidden_layer_0': 50, 'Units_hidden_layer_1': 110, 'Units_hidden_layer_2': 80, 'Units_hidden_layer_3': 160, 'optimizer': 'sgd', 'learning_rate': 0.0004, 'activation': 'relu'}. Best is trial 12 with value: 8.036427908312207.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:11,646] Trial 15 finished with value: 9.232440627550684 and parameters: {'Units_hidden_layer_0': 110, 'Units_hidden_layer_1': 60, 'Units_hidden_layer_2': 150, 'Units_hidden_layer_3': 60, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'tanh'}. Best is trial 12 with value: 8.036427908312207.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:13,148] Trial 16 finished with value: 9.761620120779053 and parameters: {'Units_hidden_layer_0': 60, 'Units_hidden_layer_1': 40, 'Units_hidden_layer_2': 60, 'Units_hidden_layer_3': 160, 'optimizer': 'sgd', 'learning_rate': 0.00030000000000000003, 'activation': 'tanh'}. Best is trial 12 with value: 8.036427908312207.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:16,817] Trial 17 finished with value: 9.635816468079911 and parameters: {'Units_hidden_layer_0': 110, 'Units_hidden_layer_1': 80, 'Units_hidden_layer_2': 170, 'Units_hidden_layer_3': 80, 'optimizer': 'sgd', 'learning_rate': 0.0006000000000000001, 'activation': 'tanh'}. Best is trial 12 with value: 8.036427908312207.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:17,529] Trial 18 finished with value: 10.351335958989743 and parameters: {'Units_hidden_layer_0': 160, 'Units_hidden_layer_1': 0, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'relu'}. Best is trial 12 with value: 8.036427908312207.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:20,204] Trial 19 finished with value: 10.839505478653878 and parameters: {'Units_hidden_layer_0': 80, 'Units_hidden_layer_1': 110, 'Units_hidden_layer_2': 130, 'Units_hidden_layer_3': 0, 'optimizer': 'sgd', 'learning_rate': 0.0004, 'activation': 'tanh'}. Best is trial 12 with value: 8.036427908312207.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:22,131] Trial 20 finished with value: 7.934963768643129 and parameters: {'Units_hidden_layer_0': 30, 'Units_hidden_layer_1': 60, 'Units_hidden_layer_2': 130, 'Units_hidden_layer_3': 150, 'optimizer': 'sgd', 'learning_rate': 0.0008, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:24,165] Trial 21 finished with value: 9.57413338760035 and parameters: {'Units_hidden_layer_0': 30, 'Units_hidden_layer_1': 70, 'Units_hidden_layer_2': 140, 'Units_hidden_layer_3': 160, 'optimizer': 'sgd', 'learning_rate': 0.0008, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:25,800] Trial 22 finished with value: 13.64612053216314 and parameters: {'Units_hidden_layer_0': 40, 'Units_hidden_layer_1': 20, 'Units_hidden_layer_2': 180, 'Units_hidden_layer_3': 180, 'optimizer': 'sgd', 'learning_rate': 0.0008, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:28,134] Trial 23 finished with value: 8.567573819447412 and parameters: {'Units_hidden_layer_0': 70, 'Units_hidden_layer_1': 100, 'Units_hidden_layer_2': 90, 'Units_hidden_layer_3': 140, 'optimizer': 'sgd', 'learning_rate': 0.0006000000000000001, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:30,622] Trial 24 finished with value: 8.164567257690884 and parameters: {'Units_hidden_layer_0': 90, 'Units_hidden_layer_1': 50, 'Units_hidden_layer_2': 120, 'Units_hidden_layer_3': 180, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:33,169] Trial 25 finished with value: 9.389799943463165 and parameters: {'Units_hidden_layer_0': 120, 'Units_hidden_layer_1': 30, 'Units_hidden_layer_2': 170, 'Units_hidden_layer_3': 90, 'optimizer': 'sgd', 'learning_rate': 0.0005, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:34,285] Trial 26 finished with value: 12.580183871266417 and parameters: {'Units_hidden_layer_0': 30, 'Units_hidden_layer_1': 70, 'Units_hidden_layer_2': 30, 'Units_hidden_layer_3': 140, 'optimizer': 'adam', 'learning_rate': 0.0009000000000000001, 'activation': 'relu'}. Best is trial 20 with value: 7.934963768643129.\n",
      "[I 2025-05-26 12:52:34,532] Trial 27 finished with value: 29.60932006969059 and parameters: {'Units_hidden_layer_0': 60, 'Units_hidden_layer_1': 90, 'Units_hidden_layer_2': 100, 'Units_hidden_layer_3': 40, 'optimizer': 'sgd', 'learning_rate': 0.0004, 'activation': 'identity'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:36,134] Trial 28 finished with value: 19.16392090809217 and parameters: {'Units_hidden_layer_0': 10, 'Units_hidden_layer_1': 50, 'Units_hidden_layer_2': 140, 'Units_hidden_layer_3': 180, 'optimizer': 'sgd', 'learning_rate': 0.0006000000000000001, 'activation': 'logistic'}. Best is trial 20 with value: 7.934963768643129.\n",
      "[I 2025-05-26 12:52:36,368] Trial 29 finished with value: 31.452916346193767 and parameters: {'Units_hidden_layer_0': 100, 'Units_hidden_layer_1': 130, 'Units_hidden_layer_2': 190, 'Units_hidden_layer_3': 150, 'optimizer': 'sgd', 'learning_rate': 0.0008, 'activation': 'identity'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:38,470] Trial 30 finished with value: 15.19414876691251 and parameters: {'Units_hidden_layer_0': 150, 'Units_hidden_layer_1': 20, 'Units_hidden_layer_2': 150, 'Units_hidden_layer_3': 190, 'optimizer': 'sgd', 'learning_rate': 0.0001, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:40,914] Trial 31 finished with value: 8.588765136943833 and parameters: {'Units_hidden_layer_0': 90, 'Units_hidden_layer_1': 50, 'Units_hidden_layer_2': 120, 'Units_hidden_layer_3': 180, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:43,527] Trial 32 finished with value: 9.174110320243944 and parameters: {'Units_hidden_layer_0': 130, 'Units_hidden_layer_1': 70, 'Units_hidden_layer_2': 110, 'Units_hidden_layer_3': 170, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:45,705] Trial 33 finished with value: 13.06911848447716 and parameters: {'Units_hidden_layer_0': 70, 'Units_hidden_layer_1': 40, 'Units_hidden_layer_2': 120, 'Units_hidden_layer_3': 200, 'optimizer': 'sgd', 'learning_rate': 0.0006000000000000001, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:48,406] Trial 34 finished with value: 17.9763329375177 and parameters: {'Units_hidden_layer_0': 90, 'Units_hidden_layer_1': 60, 'Units_hidden_layer_2': 130, 'Units_hidden_layer_3': 180, 'optimizer': 'adam', 'learning_rate': 0.0008, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "[I 2025-05-26 12:52:48,624] Trial 35 finished with value: 29.24585512846609 and parameters: {'Units_hidden_layer_0': 120, 'Units_hidden_layer_1': 80, 'Units_hidden_layer_2': 160, 'Units_hidden_layer_3': 130, 'optimizer': 'sgd', 'learning_rate': 0.0005, 'activation': 'identity'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:49,665] Trial 36 finished with value: 15.447637265642387 and parameters: {'Units_hidden_layer_0': 30, 'Units_hidden_layer_1': 40, 'Units_hidden_layer_2': 60, 'Units_hidden_layer_3': 40, 'optimizer': 'sgd', 'learning_rate': 0.0009000000000000001, 'activation': 'logistic'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:53,119] Trial 37 finished with value: 18.59862652515269 and parameters: {'Units_hidden_layer_0': 90, 'Units_hidden_layer_1': 200, 'Units_hidden_layer_2': 100, 'Units_hidden_layer_3': 170, 'optimizer': 'adam', 'learning_rate': 0.001, 'activation': 'tanh'}. Best is trial 20 with value: 7.934963768643129.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:56,217] Trial 38 finished with value: 7.704794357603482 and parameters: {'Units_hidden_layer_0': 180, 'Units_hidden_layer_1': 90, 'Units_hidden_layer_2': 120, 'Units_hidden_layer_3': 110, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'tanh'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:52:59,672] Trial 39 finished with value: 11.31642874447957 and parameters: {'Units_hidden_layer_0': 200, 'Units_hidden_layer_1': 110, 'Units_hidden_layer_2': 140, 'Units_hidden_layer_3': 100, 'optimizer': 'adam', 'learning_rate': 0.0006000000000000001, 'activation': 'relu'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:53:03,398] Trial 40 finished with value: 16.474862480356794 and parameters: {'Units_hidden_layer_0': 180, 'Units_hidden_layer_1': 90, 'Units_hidden_layer_2': 170, 'Units_hidden_layer_3': 120, 'optimizer': 'sgd', 'learning_rate': 0.0008, 'activation': 'logistic'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:53:06,288] Trial 41 finished with value: 7.927032047175265 and parameters: {'Units_hidden_layer_0': 170, 'Units_hidden_layer_1': 80, 'Units_hidden_layer_2': 110, 'Units_hidden_layer_3': 30, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'tanh'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:53:09,362] Trial 42 finished with value: 8.290416221112597 and parameters: {'Units_hidden_layer_0': 170, 'Units_hidden_layer_1': 100, 'Units_hidden_layer_2': 110, 'Units_hidden_layer_3': 30, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'tanh'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:53:12,128] Trial 43 finished with value: 9.830411946590159 and parameters: {'Units_hidden_layer_0': 170, 'Units_hidden_layer_1': 80, 'Units_hidden_layer_2': 90, 'Units_hidden_layer_3': 20, 'optimizer': 'sgd', 'learning_rate': 0.0006000000000000001, 'activation': 'tanh'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:53:15,413] Trial 44 finished with value: 11.659840014495797 and parameters: {'Units_hidden_layer_0': 150, 'Units_hidden_layer_1': 100, 'Units_hidden_layer_2': 130, 'Units_hidden_layer_3': 50, 'optimizer': 'sgd', 'learning_rate': 0.0005, 'activation': 'tanh'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:53:19,565] Trial 45 finished with value: 8.425083788140846 and parameters: {'Units_hidden_layer_0': 200, 'Units_hidden_layer_1': 150, 'Units_hidden_layer_2': 160, 'Units_hidden_layer_3': 10, 'optimizer': 'sgd', 'learning_rate': 0.0009000000000000001, 'activation': 'tanh'}. Best is trial 38 with value: 7.704794357603482.\n",
      "[I 2025-05-26 12:53:19,885] Trial 46 finished with value: 29.4911888325492 and parameters: {'Units_hidden_layer_0': 160, 'Units_hidden_layer_1': 120, 'Units_hidden_layer_2': 80, 'Units_hidden_layer_3': 60, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'identity'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:53:24,515] Trial 47 finished with value: 11.52137082293666 and parameters: {'Units_hidden_layer_0': 180, 'Units_hidden_layer_1': 170, 'Units_hidden_layer_2': 150, 'Units_hidden_layer_3': 20, 'optimizer': 'adam', 'learning_rate': 0.0008, 'activation': 'tanh'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:53:27,522] Trial 48 finished with value: 8.655163324569465 and parameters: {'Units_hidden_layer_0': 190, 'Units_hidden_layer_1': 70, 'Units_hidden_layer_2': 120, 'Units_hidden_layer_3': 100, 'optimizer': 'sgd', 'learning_rate': 0.0006000000000000001, 'activation': 'tanh'}. Best is trial 38 with value: 7.704794357603482.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-05-26 12:53:30,970] Trial 49 finished with value: 9.632123569416416 and parameters: {'Units_hidden_layer_0': 140, 'Units_hidden_layer_1': 60, 'Units_hidden_layer_2': 190, 'Units_hidden_layer_3': 120, 'optimizer': 'sgd', 'learning_rate': 0.0007000000000000001, 'activation': 'tanh'}. Best is trial 38 with value: 7.704794357603482.\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization using Optuna for 50 trials:\n",
    "study = optuna.create_study(sampler=optuna.samplers.TPESampler(),direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n",
      "Units_hidden_layer_0 :  180\n",
      "Units_hidden_layer_1 :  90\n",
      "Units_hidden_layer_2 :  120\n",
      "Units_hidden_layer_3 :  110\n",
      "optimizer :  sgd\n",
      "learning_rate :  0.0007000000000000001\n",
      "activation :  tanh\n"
     ]
    }
   ],
   "source": [
    "#Extraction of best hyperparameters and application of the model trained with the best configuration on the test set:\n",
    "best_config=study.best_trial.params\n",
    "print('Best configuration:')\n",
    "for key in best_config.keys():\n",
    "    print(key,': ',(best_config[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;tanh&#x27;, alpha=0.01,\n",
       "             hidden_layer_sizes=(180, 90, 120, 110),\n",
       "             learning_rate_init=0.0007000000000000001, max_iter=500,\n",
       "             solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor(activation=&#x27;tanh&#x27;, alpha=0.01,\n",
       "             hidden_layer_sizes=(180, 90, 120, 110),\n",
       "             learning_rate_init=0.0007000000000000001, max_iter=500,\n",
       "             solver=&#x27;sgd&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='tanh', alpha=0.01,\n",
       "             hidden_layer_sizes=(180, 90, 120, 110),\n",
       "             learning_rate_init=0.0007000000000000001, max_iter=500,\n",
       "             solver='sgd')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Implementation of the MLP-regressor with the best hyperparameter configuration:\n",
    "\n",
    "# create the hidden layers\n",
    "hidden_layers = [best_config[key] for key in sorted(best_config) if key.startswith(\"Units_hidden_layer_\") and best_config[key] > 0]\n",
    "\n",
    "best_mlp_regressor =  MLPRegressor(hidden_layer_sizes=tuple(hidden_layers),\n",
    "                                   activation=best_config[\"activation\"],\n",
    "                                   solver=best_config[\"optimizer\"],\n",
    "                                   learning_rate_init=best_config[\"learning_rate\"],\n",
    "                                   alpha=0.01,\n",
    "                                   max_iter=500)\n",
    "\n",
    "\n",
    "best_mlp_regressor.fit(x_train_scaled,y_train)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Optuna, 4 layers [180, 90, 120, 110], Test MSE: 23.7378\n",
      "Model ReLU, 2 layers [10,5], Test MSE: 34.7204\n"
     ]
    }
   ],
   "source": [
    "#Comparison of results with tuned vs not tuned ReLU-neural network:\n",
    "\n",
    "# make predictions for the best model (with optuna)\n",
    "y_pred_optuna = best_mlp_regressor.predict(x_test_scaled)\n",
    "\n",
    "# calculate the mse\n",
    "best_mlp_mse = mse(true_target=y_test, predictions=y_pred_optuna)\n",
    "  \n",
    "\n",
    "# print results\n",
    "print(f\"Model with Optuna, 4 layers [180, 90, 120, 110], Test MSE: {round(best_mlp_mse, 4)}\")\n",
    "print(f\"Model ReLU, 2 layers [10,5], Test MSE: {round(relu_mse, 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the smaller the MSE is, the better the results. In this case the model with hyperparameter tuning with Optuna performs better than the ReLU model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
